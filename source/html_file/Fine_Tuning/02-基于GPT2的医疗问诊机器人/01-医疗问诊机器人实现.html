
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../01-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/02-%E5%A4%A7%E6%A8%A1%E5%9E%8BPEFT%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95.html">
      
      
        <link rel="next" href="../03-%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/01-%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D.html">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.16">
    
    
      
        <title>2.1 医疗问诊机器人实现 - 大模型微调技术V6.1</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.7e37652d.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#gpt2" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href=".." title="大模型微调技术V6.1" class="md-header__button md-logo" aria-label="大模型微调技术V6.1" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            大模型微调技术V6.1
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              2.1 医疗问诊机器人实现
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="大模型微调技术V6.1" class="md-nav__button md-logo" aria-label="大模型微调技术V6.1" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    大模型微调技术V6.1
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" >
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    1、大模型微调的主要方式
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            1、大模型微调的主要方式
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../01-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%96%B9%E6%B3%95.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1.1 大模型Prompt-Tuning方法
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../01-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/02-%E5%A4%A7%E6%A8%A1%E5%9E%8BPEFT%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1.2 大模型PEFT微调方法
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    2、基于GPT2的医疗问诊机器人
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            2、基于GPT2的医疗问诊机器人
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    2.1 医疗问诊机器人实现
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="01-%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AE%9E%E7%8E%B0.html" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    2.1 医疗问诊机器人实现
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      学习目标
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    <span class="md-ellipsis">
      1. 项目介绍
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. 项目介绍">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 项目背景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 环境准备
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13" class="md-nav__link">
    <span class="md-ellipsis">
      1.3 项目整体结构
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    <span class="md-ellipsis">
      2. 数据处理
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. 数据处理">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 数据介绍
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 数据处理
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2.2 数据处理">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#221" class="md-nav__link">
    <span class="md-ellipsis">
      2.2.1 配置文件
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#221_1" class="md-nav__link">
    <span class="md-ellipsis">
      2.2.1 数据张量转换
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#222-dataloader" class="md-nav__link">
    <span class="md-ellipsis">
      2.2.2 获取dataloader
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2.2.2 获取dataloader">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1dataset" class="md-nav__link">
    <span class="md-ellipsis">
      （1）封装Dataset对象
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2dataloader" class="md-nav__link">
    <span class="md-ellipsis">
      （2）封装DataLoader对象
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3" class="md-nav__link">
    <span class="md-ellipsis">
      3. 模型搭建
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. 模型搭建">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 模型架构介绍
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-gpt2" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 GPT2模型准备
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4" class="md-nav__link">
    <span class="md-ellipsis">
      4. 模型训练和验证
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5" class="md-nav__link">
    <span class="md-ellipsis">
      5. 模型预测（人机交互）
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-flaskweb" class="md-nav__link">
    <span class="md-ellipsis">
      6. 基于Flask框架web开发(了解)
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    3、新零售行业评价决策系统
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            3、新零售行业评价决策系统
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../03-%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/01-%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3.1 项目背景介绍
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../03-%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/02-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%8B%E7%BB%8D.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3.2 BERT+PET方式文本分类介绍
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../03-%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/03-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3.3 BERT+PET方式数据预处理
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../03-%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/04-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3.4 BERT+PET方式模型代码实现和训练
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../03-%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/05-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%8B%E7%BB%8D.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3.5 BERT+P-Tuning方式文本分类介绍
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../03-%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/06-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3.6 BERT+P-Tuning方式数据预处理
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../03-%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/07-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3.7 BERT+P-Tuning方式模型代码实现和训练
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    4、基于ChatGLM微调多任务实战
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            4、基于ChatGLM微调多任务实战
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../04-%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/01-%E9%A1%B9%E7%9B%AE%E6%95%B4%E4%BD%93%E4%BB%8B%E7%BB%8D.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4.1 项目整体简介
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../04-%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/02-%E5%A4%9A%E4%BB%BB%E5%8A%A1%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4.2 多任务数据预处理方式
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../04-%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/03-LoRA%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4.3 LoRA方式微调ChatGLM模型代码实现和训练
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../04-%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4.4 趋动云使用《扩展》
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      学习目标
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    <span class="md-ellipsis">
      1. 项目介绍
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. 项目介绍">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 项目背景
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 环境准备
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13" class="md-nav__link">
    <span class="md-ellipsis">
      1.3 项目整体结构
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    <span class="md-ellipsis">
      2. 数据处理
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. 数据处理">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 数据介绍
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 数据处理
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2.2 数据处理">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#221" class="md-nav__link">
    <span class="md-ellipsis">
      2.2.1 配置文件
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#221_1" class="md-nav__link">
    <span class="md-ellipsis">
      2.2.1 数据张量转换
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#222-dataloader" class="md-nav__link">
    <span class="md-ellipsis">
      2.2.2 获取dataloader
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2.2.2 获取dataloader">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1dataset" class="md-nav__link">
    <span class="md-ellipsis">
      （1）封装Dataset对象
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2dataloader" class="md-nav__link">
    <span class="md-ellipsis">
      （2）封装DataLoader对象
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3" class="md-nav__link">
    <span class="md-ellipsis">
      3. 模型搭建
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. 模型搭建">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 模型架构介绍
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-gpt2" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 GPT2模型准备
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4" class="md-nav__link">
    <span class="md-ellipsis">
      4. 模型训练和验证
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5" class="md-nav__link">
    <span class="md-ellipsis">
      5. 模型预测（人机交互）
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-flaskweb" class="md-nav__link">
    <span class="md-ellipsis">
      6. 基于Flask框架web开发(了解)
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="gpt2">基于GPT2搭建医疗问诊机器人<a class="headerlink" href="#gpt2" title="Permanent link">&para;</a></h1>
<hr />
<h2 id="_1">学习目标<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h2>
<ul>
<li>理解医疗问诊机器人的开发背景.</li>
<li>了解企业中聊天机器人的应用场景</li>
<li>掌握基于GPT2模型搭建医疗问诊机器人的实现过程</li>
</ul>
<hr />
<h2 id="1">1. 项目介绍<a class="headerlink" href="#1" title="Permanent link">&para;</a></h2>
<h3 id="11">1.1 项目背景<a class="headerlink" href="#11" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>聊天机器人是一种基于自然语言处理技术的智能对话系统，能够模拟人类的自然语言交流，与用户进行对话和互动。聊天机器人能够理解用户的问题或指令，并给出相应的回答或建议。其目标是提供友好、智能、自然的对话体验. </p>
</li>
<li>
<p>当前，聊天机器人在多个领域得到广泛应用。首先，它们常用于在线客服系统，能够快速、准确地回答用户的常见问题，解决疑问。其次，聊天机器人可以作为个人助手，提供个性化的推荐、建议和日程安排等服务，提升用户体验。此外，聊天机器人还被应用于社交娱乐、语言学习、旅游指南等领域，为用户提供有趣、便捷的对话体验.</p>
</li>
<li>常见的相关聊天机器人产品：</li>
</ul>
<div align=center><img src="./img/01.png" style="zoom:70%" ><img/></div>

<blockquote>
<p>微软小冰：微软公司开发。它具备自然语言处理、情感分析和对话生成等功能，能够与用户进行智能对话，提供情感支持和娱乐等服务。</p>
<p>阿里云小蜜：阿里云公司推出，提供了丰富的智能对话服务。它具备自然语言处理和对话管理能力，支持多领域的应用场景，如在线客服、智能助手和虚拟导购等。</p>
<p>百度智能云小度：百度智能云开发，提供了多领域的智能对话能力。小度机器人可应用于家庭助理、智能音箱和移动应用等场景，通过语音和文本交互与用户进行智能对话，提供信息查询、音乐播放和日程安排等功能。</p>
</blockquote>
<p>本项目**基于医疗领域数据构建了智能医疗问答系统**，目的是为为用户提供准确、高效、优质的医疗问答服务。</p>
<h3 id="12">1.2 环境准备<a class="headerlink" href="#12" title="Permanent link">&para;</a></h3>
<ul>
<li>python==3.10</li>
<li>transformers==4.40.2</li>
<li>torch==2.5.1+cu121</li>
</ul>
<h3 id="13">1.3 项目整体结构<a class="headerlink" href="#13" title="Permanent link">&para;</a></h3>
<div align=center><img src="./img/02.png" style="zoom:60%" ><img/></div>

<hr />
<p><strong>整体代码结构：</strong></p>
<p><img alt="image-20250817174320793" src="img/image-20250817174320793.png" /></p>
<h2 id="2">2. 数据处理<a class="headerlink" href="#2" title="Permanent link">&para;</a></h2>
<h3 id="21">2.1 数据介绍<a class="headerlink" href="#21" title="Permanent link">&para;</a></h3>
<ul>
<li>数据存放位置：llm_tuning/Gpt2_Chatbot/data</li>
<li>data文件夹中存有原始训练语料为train.txt。train.txt的格式如下，每段闲聊之间间隔一行，格式如下：</li>
</ul>
<div class="highlight"><pre><span></span><code>帕金森叠加综合征的辅助治疗有些什么？
综合治疗；康复训练；生活护理指导；低频重复经颅磁刺激治疗

卵巢癌肉瘤的影像学检查有些什么？
超声漏诊；声像图；MR检查；肿物超声；术前超声；CT检查
</code></pre></div>
<h3 id="22">2.2 数据处理<a class="headerlink" href="#22" title="Permanent link">&para;</a></h3>
<ul>
<li>目的：将中文文本数据处理成模型能够识别的张量形式，并将上述文本进行张量的转换</li>
<li>实现过程：<ul>
<li>运行preprocess.py，对data/train.txt对话语料进行tokenize，然后进行序列化保存到data/train.pkl。train.pkl中序列化的对象的类型为List[List],记录对话列表中,每个对话包含的token。</li>
</ul>
</li>
</ul>
<hr />
<h4 id="221">2.2.1 配置文件<a class="headerlink" href="#221" title="Permanent link">&para;</a></h4>
<ul>
<li>代码路径：llm_tuning/Gpt2_Chatbot/parameter_config.py</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>

<span class="n">base_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="vm">__file__</span><span class="p">))</span>
<span class="c1"># print(f&#39;base_dir--&gt;{base_dir}&#39;)</span>

<span class="k">class</span><span class="w"> </span><span class="nc">ParameterConfig</span><span class="p">():</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
        <span class="c1"># self.device = torch.device(&#39;mps&#39; if torch.cuda.is_available() else &#39;cpu&#39;)</span>
        <span class="c1"># 词典路径：在vocab文件夹里面</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s1">&#39;vocab/vocab.txt&#39;</span><span class="p">)</span>
        <span class="c1"># 训练文件路径</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s1">&#39;data/medical_train.pkl&#39;</span><span class="p">)</span>
        <span class="c1"># 验证数据文件路径</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valid_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s1">&#39;data/medical_valid.pkl&#39;</span><span class="p">)</span>
        <span class="c1"># 模型配置文件</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config_json</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s1">&#39;config/config.json&#39;</span><span class="p">)</span>
        <span class="c1"># 模型保存路径</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_model_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s1">&#39;save_model&#39;</span><span class="p">)</span>
        <span class="c1"># 如果你有预训练模型就写上路径（我们本次没有直接运用GPT2预训练好的模型，而是仅只用了该模型的框架）</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pretrained_model</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
        <span class="c1"># 保存对话语料</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_samples_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s1">&#39;sample&#39;</span><span class="p">)</span>
        <span class="c1"># 忽略一些字符：句子需要长度补齐，针对补的部分，没有意义，所以一般不进行梯度更新</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ignore_index</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span>
        <span class="c1"># 历史对话句子的长度</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_history_len</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># &quot;dialogue history的最大长度&quot;</span>
        <span class="c1"># 每一个完整对话的句子最大长度</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_len</span> <span class="o">=</span> <span class="mi">300</span>  <span class="c1"># &#39;每个utterance的最大长度,超过指定长度则进行截断,默认25&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">repetition_penalty</span> <span class="o">=</span> <span class="mf">5.0</span>  <span class="c1"># &quot;重复惩罚参数，若生成的对话重复性较高，可适当提高该参数&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">topk</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># &#39;保留概率最高的topk个token。默认4&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">topp</span> <span class="o">=</span> <span class="mf">0.7</span>  <span class="c1"># &#39;保留累积概率top个token。默认0.7&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">8</span>  <span class="c1"># 一个批次几个样本</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">4</span>  <span class="c1"># 训练几轮</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_step</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># 多少步汇报一次loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="mf">2.6e-5</span>
        <span class="c1"># eps，为了增加数值计算的稳定性而加到分母里的项，其为了防止在实现中除以零</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="mf">1.0e-09</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_grad_norm</span> <span class="o">=</span> <span class="mf">2.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="mi">4</span>  <span class="c1"># 梯度累积的步数</span>
        <span class="c1"># 使用Warmup预热学习率的方式,即先用最初的小学习率训练，然后每个step增大一点点，直到达到最初设置的比较大的学习率时（注：此时预热学习率完成），采用最初设置的学习率进行训练（注：预热学习率完成后的训练过程，学习率是衰减的），有助于使模型收敛速度变快，效果更佳。默认.warmup_steps = 4000</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span> <span class="o">=</span> <span class="mi">100</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">pc</span> <span class="o">=</span> <span class="n">ParameterConfig</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">pc</span><span class="o">.</span><span class="n">train_path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">pc</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</code></pre></div>
<h4 id="221_1">2.2.1 数据张量转换<a class="headerlink" href="#221_1" title="Permanent link">&para;</a></h4>
<ul>
<li>代码路径：llm_tuning/Gpt2_Chatbot/data_preprocess/preprocess.py</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">BertTokenizerFast</span><span class="p">,</span> <span class="n">BertTokenizer</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pickle</span>  <span class="c1"># 保存pkl文件的命令</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>  <span class="c1"># 加载进度条</span>


<span class="k">def</span><span class="w"> </span><span class="nf">data_preprocess</span><span class="p">(</span><span class="n">train_txt_path</span><span class="p">,</span> <span class="n">train_pkl_path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    对原始语料进行tokenizer，将每段对话处理成如下形式：&quot;[CLS]sentence1[SEP]sentence2[SEP]sentence3[SEP]&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># BertTokenizerFast相比BertTokenizer，速度更快，并且提供了 字节级别精确对齐 的 offset mapping（可以知道 token 对应原始文本的字符位置</span>
    <span class="c1"># tokenizer = BertTokenizerFast.from_pretrained(r&#39;D:\workspace\python\llm_tuning\bert-base-chinese&#39;)</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizerFast</span><span class="p">(</span><span class="s1">&#39;../vocab/vocab.txt&#39;</span><span class="p">,</span>
                                  <span class="n">sep_token</span><span class="o">=</span><span class="s2">&quot;[SEP]&quot;</span><span class="p">,</span>
                                  <span class="n">pad_token</span><span class="o">=</span><span class="s2">&quot;[PAD]&quot;</span><span class="p">,</span>
                                  <span class="n">cls_token</span><span class="o">=</span><span class="s2">&quot;[CLS]&quot;</span><span class="p">)</span>
    <span class="c1"># print(f&#39;tokenizer.vocab_size--&gt;{tokenizer.vocab_size}&#39;)</span>

    <span class="n">sep_id</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">sep_token_id</span>  <span class="c1"># 获取分隔符[SEP]的token ID</span>
    <span class="n">cls_id</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">cls_token_id</span>  <span class="c1"># 获取起始符[CLS]的token ID</span>
    <span class="c1"># print(f&#39;sep_id--&gt;{sep_id}&#39;)</span>
    <span class="c1"># print(f&#39;cls_id--&gt;{cls_id}&#39;)</span>

    <span class="c1"># 读取训练数据集</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">train_txt_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    <span class="c1"># print(f&#39;data--&gt;{data}&#39;)</span>
    <span class="c1"># 根据换行符区分不同的对话段落，需要区分Windows和Linux\mac环境下的换行符</span>
    <span class="k">if</span> <span class="s2">&quot;</span><span class="se">\r\n</span><span class="s2">&quot;</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
        <span class="n">train_data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\r\n\r\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">train_data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="c1"># print(f&#39;len(train_data)--&gt;{len(train_data)}&#39;)  # 打印对话段落数量</span>
    <span class="c1"># print(f&#39;train_data[:2]--&gt;{train_data[:2]}&#39;)</span>

    <span class="c1"># 保存所有的对话数据,每条数据的格式为：&quot;[CLS]seq1[SEP]seq2[SEP]seq3[SEP]&quot;</span>
    <span class="n">dialogue_len</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># 记录所有对话tokenize分词之后的长度，用于统计中位数与均值</span>
    <span class="n">dialogue_list</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># 记录所有对话</span>

    <span class="c1"># 遍历训练数据，其中enumerate用于获取每个对话的索引和内容，tqdm用于显示进度条</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">dialogue</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tqdm</span><span class="p">(</span><span class="n">train_data</span><span class="p">)):</span>
        <span class="c1"># 根据不同的换行符分割对话，以处理数据集中的不一致性</span>
        <span class="k">if</span> <span class="s2">&quot;</span><span class="se">\r\n</span><span class="s2">&quot;</span> <span class="ow">in</span> <span class="n">dialogue</span><span class="p">:</span>
            <span class="n">sequences</span> <span class="o">=</span> <span class="n">dialogue</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\r\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sequences</span> <span class="o">=</span> <span class="n">dialogue</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># print(f&#39;sequences--&gt;{sequences}&#39;)</span>

        <span class="c1"># 初始化input_ids列表，用于存储所有对话的tokenized版本, 每个dialogue以[CLS]seq1[sep]seq2[sep]</span>
        <span class="n">input_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">cls_id</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">sequence</span> <span class="ow">in</span> <span class="n">sequences</span><span class="p">:</span>
            <span class="c1"># 将每个对话句子进行tokenize，并将结果拼接到input_ids列表中</span>
            <span class="n">input_ids</span> <span class="o">+=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">sequence</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="c1"># 每个seq之后添加[SEP]，表示seqs会话结束</span>
            <span class="n">input_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sep_id</span><span class="p">)</span>
        <span class="c1"># print(f&#39;input_ids--&gt;{input_ids}&#39;)</span>

        <span class="c1"># 将对话的tokenize后的长度添加到对话长度列表中</span>
        <span class="n">dialogue_len</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">))</span>
        <span class="c1"># 将tokenize后的对话添加到对话列表中</span>
        <span class="n">dialogue_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
        <span class="c1"># break</span>
    <span class="c1"># print(f&#39;dialogue_list--&gt;{dialogue_list}&#39;)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;dialogue_len--&gt;</span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">dialogue_len</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">dialogue_len</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="c1"># 保存对话列表数据到训练数据的pickle文件中</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">train_pkl_path</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">dialogue_list</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">train_txt_path</span> <span class="o">=</span> <span class="s1">&#39;../data/medical_train.txt&#39;</span>
    <span class="n">train_pkl_path</span> <span class="o">=</span> <span class="s1">&#39;../data/medical_train.pkl&#39;</span>
    <span class="n">data_preprocess</span><span class="p">(</span><span class="n">train_txt_path</span><span class="p">,</span> <span class="n">train_pkl_path</span><span class="p">)</span>

    <span class="n">valid_txt_path</span> <span class="o">=</span> <span class="s1">&#39;../data/medical_valid.txt&#39;</span>
    <span class="n">valid_pkl_path</span> <span class="o">=</span> <span class="s1">&#39;../data/medical_valid.pkl&#39;</span>
    <span class="n">data_preprocess</span><span class="p">(</span><span class="n">valid_txt_path</span><span class="p">,</span> <span class="n">valid_pkl_path</span><span class="p">)</span>
</code></pre></div>
<hr />
<h4 id="222-dataloader">2.2.2 获取dataloader<a class="headerlink" href="#222-dataloader" title="Permanent link">&para;</a></h4>
<h5 id="1dataset">（1）封装Dataset对象<a class="headerlink" href="#1dataset" title="Permanent link">&para;</a></h5>
<ul>
<li>代码路径：llm_tuning/Gpt2_Chatbot/data_preprocess/dataset.py</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span>  <span class="c1"># 导入Dataset模块，用于定义自定义数据集</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>  <span class="c1"># 导入torch模块，用于处理张量和构建神经网络</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pickle</span>


<span class="c1"># 自定义数据集类，继承自Dataset类</span>
<span class="k">class</span><span class="w"> </span><span class="nc">MyDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_list</span><span class="p">,</span> <span class="n">max_len</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        初始化函数，用于设置数据集的属性</span>
<span class="sd">        :param input_list: 输入列表，包含所有对话的tokenize后的输入序列</span>
<span class="sd">        :param max_len: 最大序列长度，用于对输入进行截断或填充</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_list</span> <span class="o">=</span> <span class="n">input_list</span>  <span class="c1"># 将输入列表赋值给数据集的input_list属性</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_len</span> <span class="o">=</span> <span class="n">max_len</span>  <span class="c1"># 将最大序列长度赋值给数据集的max_len属性</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_list</span><span class="p">)</span>  <span class="c1"># 返回数据集的长度</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="n">input_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_list</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>  <span class="c1"># 获取给定索引处的输入序列</span>
        <span class="c1"># print(f&#39;input_ids--&gt;{input_ids}&#39;)</span>

        <span class="c1"># 根据最大序列长度对输入进行截断或填充（填充逻辑在dataloader文件中实现）</span>
        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">max_len</span><span class="p">]</span>  <span class="c1"># 截断</span>
        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>  <span class="c1"># 将输入序列转换为张量long类型</span>
        <span class="k">return</span> <span class="n">input_ids</span>  <span class="c1"># 返回样本的输入序列张量</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;../data/medical_train.pkl&#39;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">train_input_list</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>  <span class="c1"># 从文件中加载输入列</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;train_input_list--&gt;</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_input_list</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;train_input_list--&gt;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">train_input_list</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;train_input_list--&gt;</span><span class="si">{</span><span class="n">train_input_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="n">mydataset</span> <span class="o">=</span> <span class="n">MyDataset</span><span class="p">(</span><span class="n">input_list</span><span class="o">=</span><span class="n">train_input_list</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;mydataset--&gt;</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">mydataset</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">mydataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div>
<hr />
<h5 id="2dataloader">（2）封装DataLoader对象<a class="headerlink" href="#2dataloader" title="Permanent link">&para;</a></h5>
<ul>
<li>代码路径：/home/user/ProjectStudy/Gpt2_Chatbot/data_preprocess/dataloader.py</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.utils.rnn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">rnn_utils</span>  <span class="c1"># 导入rnn_utils模块，用于处理可变长度序列的填充和排序</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>  <span class="c1"># 导入Dataset和DataLoader模块，用于加载和处理数据集</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pickle</span>  <span class="c1"># 导入pickle模块，用于序列化和反序列化Python对象</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">Gpt2_Chatbot.data_preprocess.dataset</span><span class="w"> </span><span class="kn">import</span> <span class="n">MyDataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">Gpt2_Chatbot.parameter_config</span><span class="w"> </span><span class="kn">import</span> <span class="n">ParameterConfig</span>

<span class="n">params</span> <span class="o">=</span> <span class="n">ParameterConfig</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">load_dataset</span><span class="p">(</span><span class="n">train_path</span><span class="p">,</span> <span class="n">valid_path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    加载训练集和验证集</span>
<span class="sd">    :param train_path: 训练数据集路径</span>
<span class="sd">    :return: 训练数据集和验证数据集</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">train_path</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">train_input_list</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>  <span class="c1"># 从文件中加载输入列表</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">valid_path</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">valid_input_list</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>  <span class="c1"># 从文件中加载输入列表</span>
    <span class="c1"># 划分训练集与验证集</span>
    <span class="c1"># print(len(train_input_list))  # 打印输入列表的长度</span>
    <span class="c1"># print(train_input_list[0])</span>

    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">MyDataset</span><span class="p">(</span><span class="n">train_input_list</span><span class="p">,</span> <span class="n">params</span><span class="o">.</span><span class="n">max_len</span><span class="p">)</span>  <span class="c1"># 创建训练数据集对象</span>
    <span class="n">val_dataset</span> <span class="o">=</span> <span class="n">MyDataset</span><span class="p">(</span><span class="n">valid_input_list</span><span class="p">,</span> <span class="n">params</span><span class="o">.</span><span class="n">max_len</span><span class="p">)</span>  <span class="c1"># 创建验证数据集对象</span>
    <span class="k">return</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">val_dataset</span>  <span class="c1"># 返回训练数据集和验证数据集</span>


<span class="k">def</span><span class="w"> </span><span class="nf">collate_fn</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    自定义的collate_fn函数，用于将数据集中的样本进行批处理</span>
<span class="sd">    :param batch: 样本列表</span>
<span class="sd">    :return: 经过填充的输入序列张量和标签序列张量</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># 对输入序列进行填充，使其长度一致</span>
    <span class="c1"># rnn_utils.pad_sequence：将根据一个batch中，最大句子长度，进行补齐</span>
    <span class="c1"># 参数batch_first=True表示返回的张量形状为(batch_size, max_seq_length)</span>
    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">rnn_utils</span><span class="o">.</span><span class="n">pad_sequence</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">padding_value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># 对标签序列进行填充, 使其长度一致, 用-100进行填充(计算损失值会忽略-100)</span>
    <span class="c1"># 后续计算损失时, 预测的标签和真实的标签需要进行错一位(input_ids和labels一样)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">rnn_utils</span><span class="o">.</span><span class="n">pad_sequence</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">padding_value</span><span class="o">=-</span><span class="mi">100</span><span class="p">)</span>
    <span class="c1"># print(f&#39;labels--&gt;{labels}&#39;)</span>
    <span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">labels</span>  <span class="c1"># 返回经过填充的输入序列张量和标签序列张量</span>


<span class="k">def</span><span class="w"> </span><span class="nf">get_dataloader</span><span class="p">(</span><span class="n">train_path</span><span class="p">,</span> <span class="n">valid_path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    获取训练数据集和验证数据集的DataLoader对象</span>
<span class="sd">    :param train_path: 训练数据集路径</span>
<span class="sd">    :param valid_path: 验证数据集路径</span>
<span class="sd">    :return: 训练数据集的DataLoader对象和验证数据集的DataLoader对象</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">train_dataset</span><span class="p">,</span> <span class="n">val_dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">train_path</span><span class="p">,</span> <span class="n">valid_path</span><span class="p">)</span>  <span class="c1"># 加载训练数据集和验证数据集</span>
    <span class="c1"># print(f&#39;train_dataset--&gt;{len(train_dataset)}&#39;)</span>
    <span class="c1"># print(f&#39;val_dataset--&gt;{len(val_dataset)}&#39;)</span>

    <span class="c1"># 创建训练数据集的DataLoader对象</span>
    <span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span>
                                  <span class="n">batch_size</span><span class="o">=</span><span class="n">params</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                                  <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                  <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
                                  <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># 创建验证数据集的DataLoader对象</span>
    <span class="n">validate_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span>
                                     <span class="n">batch_size</span><span class="o">=</span><span class="n">params</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                                     <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                     <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
                                     <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># 返回训练数据集的DataLoader对象和验证数据集的DataLoader对象</span>
    <span class="k">return</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">validate_dataloader</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">validate_dataloader</span> <span class="o">=</span> <span class="n">get_dataloader</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">train_path</span><span class="p">,</span> <span class="n">params</span><span class="o">.</span><span class="n">valid_path</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_dataloader</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;input_ids--&gt;</span><span class="si">{</span><span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;labels--&gt;</span><span class="si">{</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">break</span>
</code></pre></div>
<hr />
<h2 id="3">3. 模型搭建<a class="headerlink" href="#3" title="Permanent link">&para;</a></h2>
<h3 id="31">3.1 模型架构介绍<a class="headerlink" href="#31" title="Permanent link">&para;</a></h3>
<div align=center><img src="./img/04.png" style="zoom:70%" ><img/></div>

<ul>
<li>
<p>模型架构解析：</p>
<ul>
<li>输入层：词嵌入层：WordEmbedding +位置嵌入层：PositionEmbedding</li>
<li>中间层：Transformer的Decoder模块---12层</li>
<li>输出层：线性全连接层</li>
</ul>
</li>
<li>
<p>模型主要参数简介(详见模型的config.json文件):</p>
<ul>
<li>n_embd: 768</li>
<li>n_head: 12</li>
<li>n_layer: 12</li>
<li>n_positions: 1024</li>
<li>vocab_size: 13317</li>
</ul>
</li>
</ul>
<hr />
<h3 id="32-gpt2">3.2 GPT2模型准备<a class="headerlink" href="#32-gpt2" title="Permanent link">&para;</a></h3>
<ul>
<li>本次项目使用GPT2的预训练模型，因此不需要额外搭建Model类，下面代码是如何直接加载使用GPT2预训练模型</li>
<li>代码示例:</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">GPT2LMHeadModel</span><span class="p">,</span> <span class="n">GPT2Config</span>
<span class="c1"># 创建模型</span>
<span class="k">if</span> <span class="n">params</span><span class="o">.</span><span class="n">pretrained_model</span><span class="p">:</span>  
    <span class="c1"># 加载预训练模型</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">GPT2LMHeadModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">pretrained_model</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>  
    <span class="c1"># 初始化模型</span>
    <span class="n">model_config</span> <span class="o">=</span> <span class="n">GPT2Config</span><span class="o">.</span><span class="n">from_json_file</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">config_json</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">GPT2LMHeadModel</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">model_config</span><span class="p">)</span>
</code></pre></div>
<ul>
<li>如果使用第二种方式，需要配置模型的参数</li>
</ul>
<p>位置：llm_tuning/Gpt2_Chatbot/config/config.json</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;activation_function&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;gelu_new&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;architectures&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;GPT2LMHeadModel&quot;</span>
<span class="w">  </span><span class="p">],</span>
<span class="w">  </span><span class="nt">&quot;attn_pdrop&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.1</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;bos_token_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">50256</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;embd_pdrop&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.1</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;eos_token_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">50256</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;gradient_checkpointing&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;initializer_range&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.02</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;layer_norm_epsilon&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1e-05</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;model_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;gpt2&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;n_ctx&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1024</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;n_embd&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">768</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;n_head&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">12</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;n_inner&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;n_layer&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">12</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;n_positions&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1024</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;output_past&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;resid_pdrop&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.1</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;summary_activation&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;summary_first_dropout&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.1</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;summary_proj_to_labels&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;summary_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;cls_index&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;summary_use_proj&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;task_specific_params&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;text-generation&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;do_sample&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;max_length&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">400</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;tokenizer_class&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;BertTokenizer&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;transformers_version&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;4.2.0&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;use_cache&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;vocab_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">13317</span>
<span class="p">}</span>
</code></pre></div>
<h2 id="4">4. 模型训练和验证<a class="headerlink" href="#4" title="Permanent link">&para;</a></h2>
<ul>
<li>主要代码</li>
</ul>
<div align=center><img src="./img/05.png" style="zoom:70%" ><img/></div>

<ul>
<li>
<p>代码位置</p>
</li>
<li>
<p>训练主函数：llm_tuning/Gpt2_Chatbot/train.py</p>
</li>
<li>
<p>辅助工具类：llm_tuning/Gpt2_Chatbot/functions_tools.py</p>
</li>
</ul>
<hr />
<ul>
<li>trian.py代码解析</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datetime</span><span class="w"> </span><span class="kn">import</span> <span class="n">datetime</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">AdamW</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">GPT2LMHeadModel</span><span class="p">,</span> <span class="n">GPT2Config</span><span class="p">,</span> <span class="n">BertTokenizerFast</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_linear_schedule_with_warmup</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">Gpt2_Chatbot.data_preprocess.dataloader</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_dataloader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">Gpt2_Chatbot.functions_tools</span><span class="w"> </span><span class="kn">import</span> <span class="n">calculate_acc</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">Gpt2_Chatbot.parameter_config</span><span class="w"> </span><span class="kn">import</span> <span class="n">ParameterConfig</span>


<span class="k">def</span><span class="w"> </span><span class="nf">train_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    :param model: GPT2模型</span>
<span class="sd">    :param train_dataloader: 训练数据集</span>
<span class="sd">    :param optimizer: 优化器：更新参数</span>
<span class="sd">    :param scheduler: 学习率预热</span>
<span class="sd">    :param epoch: 当前的轮次</span>
<span class="sd">    :param args: 模型配置文件的参数对象</span>
<span class="sd">    :return: 每次迭代的平均损失值</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;start training...&quot;</span><span class="p">)</span>
    <span class="c1"># 指明模型训练</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">device</span>
    <span class="c1"># 对于ignore_index的label token不计算梯度</span>
    <span class="n">ignore_index</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">ignore_index</span>
    <span class="n">epoch_start_time</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># 记录下整个epoch的loss的总和</span>

    <span class="c1"># epoch_correct_num: 每个epoch中,output预测正确的word的数量</span>
    <span class="c1"># epoch_total_num: 每个epoch中,output预测的word的总数量</span>
    <span class="n">epoch_correct_num</span><span class="p">,</span> <span class="n">epoch_total_num</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tqdm</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)):</span>
        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="c1"># print(f&#39;input_ids--&gt;{input_ids.shape}&#39;)</span>
        <span class="c1"># print(f&#39;labels--&gt;{labels.shape}&#39;)</span>
        <span class="c1"># 如果对模型输入不仅包含input还包含标签，那么得到结果直接就有loss值。其中模型内部会把 logits/labels 做位移对齐（labels 通常可以等于 input_ids， 模型内部会把 logits[..., :-1, :] 与 labels[..., 1:] 对齐计算损失），并对被标为 -100 的 label 忽略不计。</span>
        <span class="c1"># 如果对模型的输入只有input，那么模型的结果不会含有loss值，此时，可以自定义函数来计算损失</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
        <span class="c1"># print(f&#39;outputs--&gt;{outputs}&#39;)</span>
        <span class="c1"># print(f&#39;outputs--&gt;{outputs.keys()}&#39;)</span>
        <span class="c1"># print(f&#39;outputs.logits--&gt;{outputs.logits.shape}&#39;)</span>
        <span class="c1"># print(f&#39;outputs.loss--&gt;{outputs.loss}&#39;)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">logits</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">loss</span>

        <span class="c1"># 累加当前损失到总损失中</span>
        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="c1"># 统计该batch的预测token的正确数与总数</span>
        <span class="n">batch_correct_num</span><span class="p">,</span> <span class="n">batch_total_num</span> <span class="o">=</span> <span class="n">calculate_acc</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span>
                                                           <span class="n">labels</span><span class="p">,</span>
                                                           <span class="n">ignore_index</span><span class="o">=</span><span class="n">ignore_index</span><span class="p">)</span>
        <span class="c1"># print(f&#39;batch_correct_num--&gt;{batch_correct_num}&#39;)</span>
        <span class="c1"># print(f&#39;batch_total_num--&gt;{batch_total_num}&#39;)</span>

        <span class="c1"># 计算该batch的accuracy</span>
        <span class="n">batch_acc</span> <span class="o">=</span> <span class="n">batch_correct_num</span> <span class="o">/</span> <span class="n">batch_total_num</span>
        <span class="c1"># 统计该epoch的预测token的正确数与总数</span>
        <span class="n">epoch_correct_num</span> <span class="o">+=</span> <span class="n">batch_correct_num</span>
        <span class="n">epoch_total_num</span> <span class="o">+=</span> <span class="n">batch_total_num</span>

<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        self.gradient_accumulation_steps = 4 累积的步数</span>
<span class="sd">        如果设置了梯度累积步数且大于1，则需要对损失进行相应的调整</span>
<span class="sd">        这是因为在累积步数内，损失会被累积计算，而不是在每个训练步骤后立即更新权重</span>
<span class="sd">        通过将损失除以梯度累积步数，可以得到每次累积后实际应该应用的平均损失        </span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">/</span> <span class="n">args</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span>

        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">parameters</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">max_norm</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">max_grad_norm</span><span class="p">)</span>

        <span class="c1"># 在到达梯度累计的步数之后，执行参数更新</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">batch_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">args</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># 更新参数</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="c1"># 更新学习率</span>
            <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="c1"># 清空梯度信息</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># 当batch_idx加1能被args.loss_step整除时，输出当前批次的训练信息</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">batch_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">args</span><span class="o">.</span><span class="n">loss_step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">&quot;batch </span><span class="si">{}</span><span class="s2"> of epoch </span><span class="si">{}</span><span class="s2">, loss </span><span class="si">{:.4f}</span><span class="s2">, batch_acc </span><span class="si">{:.4f}</span><span class="s2">, lr </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">batch_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span><span class="p">,</span>
                    <span class="n">batch_acc</span><span class="p">,</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">get_last_lr</span><span class="p">()[</span><span class="mi">0</span><span class="p">]))</span>
            <span class="c1"># break</span>

    <span class="c1"># 记录当前epoch的平均loss与accuracy</span>
    <span class="n">epoch_mean_loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)</span>
    <span class="n">epoch_mean_acc</span> <span class="o">=</span> <span class="n">epoch_correct_num</span> <span class="o">/</span> <span class="n">epoch_total_num</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;epoch </span><span class="si">{}</span><span class="s2">: loss </span><span class="si">{:.4f}</span><span class="s2">, predict_acc </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">epoch_mean_loss</span><span class="p">,</span> <span class="n">epoch_mean_acc</span><span class="p">))</span>

    <span class="c1"># 在每个epoch结束时，根据条件保存模型</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">epoch</span> <span class="o">==</span> <span class="n">args</span><span class="o">.</span><span class="n">epochs</span><span class="p">:</span>
        <span class="c1"># 打印保存模型的信息</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;正在保存第 </span><span class="si">{}</span><span class="s1"> 轮次模型&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="c1"># 构造模型保存路径</span>
        <span class="n">model_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">save_model_path</span><span class="p">,</span> <span class="s1">&#39;bj_epoch</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="c1"># 如果模型保存路径不存在，则创建该目录</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">model_path</span><span class="p">):</span>
            <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
        <span class="c1"># 保存预训练模型的方式</span>
        <span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
        <span class="c1"># 打印完成信息</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;第 </span><span class="si">{}</span><span class="s1"> 轮次模型保存完成。&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="c1"># 记录epoch完成的时间</span>
        <span class="n">epoch_finish_time</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
        <span class="c1"># 打印完成该轮次所需的时间</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;完成本轮次所花时间为: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch_finish_time</span> <span class="o">-</span> <span class="n">epoch_start_time</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">epoch_mean_loss</span>


<span class="k">def</span><span class="w"> </span><span class="nf">validate_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">validate_dataloader</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    验证模型在一个epoch上的表现。</span>
<span class="sd">    :param model: 要验证的模型</span>
<span class="sd">    :param validate_dataloader: 验证数据加载器</span>
<span class="sd">    :param epoch: 当前验证的epoch数</span>
<span class="sd">    :param args: 包含设备信息等的参数对象</span>
<span class="sd">    :return: 当前epoch的平均损失</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;start validating...&quot;</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># 将模型设置为评估模式</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">device</span>  <span class="c1"># 获取设备信息</span>
    <span class="n">epoch_start_time</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>  <span class="c1"># 记录epoch开始时间</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># 初始化总损失</span>

    <span class="c1"># 捕获cuda out of memory exception</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>  <span class="c1"># 禁止计算梯度以节省内存</span>
        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tqdm</span><span class="p">(</span><span class="n">validate_dataloader</span><span class="p">)):</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># 将输入数据移动到指定设备</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># 将标签移动到指定设备</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>  <span class="c1"># 模型前向传播</span>

            <span class="c1"># logits = outputs.logits</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">loss</span>  <span class="c1"># 获取损失</span>
            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>  <span class="c1"># 累加损失</span>

    <span class="c1"># 记录当前epoch的平均loss</span>
    <span class="n">epoch_mean_loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">validate_dataloader</span><span class="p">)</span>  <span class="c1"># 计算平均损失</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;第 </span><span class="si">{}</span><span class="s2"> 轮的模型在验证集上的平均损失为：</span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">epoch_mean_loss</span><span class="p">))</span>
    <span class="n">epoch_finish_time</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>  <span class="c1"># 记录epoch结束时间</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;完成本轮次验证所花时间为: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch_finish_time</span> <span class="o">-</span> <span class="n">epoch_start_time</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">epoch_mean_loss</span>  <span class="c1"># 返回平均损失</span>


<span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">validate_dataloader</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
    <span class="c1"># eps，为了增加数值计算的稳定性而加到分母里的项，其为了防止在实现中除以零</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>
    <span class="c1"># 这里使用学习率预热处理优化</span>
    <span class="c1"># print(f&#39;每个轮次中的批次数--&gt;{len(train_dataloader)}&#39;)</span>
    <span class="c1"># t_total为使用梯度累积时，模型训练完毕一共 更新参数的次数</span>
    <span class="n">t_total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)</span> <span class="o">//</span> <span class="n">args</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">epochs</span>
    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">get_linear_schedule_with_warmup</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span>
                                                <span class="n">num_warmup_steps</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">warmup_steps</span><span class="p">,</span>
                                                <span class="n">num_training_steps</span><span class="o">=</span><span class="n">t_total</span><span class="p">)</span>

    <span class="c1"># 用于记录每个epoch训练和验证的loss</span>
    <span class="n">train_losses</span><span class="p">,</span> <span class="n">validate_losses</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="c1"># 记录验证集的最小loss</span>
    <span class="n">best_val_loss</span> <span class="o">=</span> <span class="mi">10000</span>
    <span class="c1"># 开始训练</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">epochs</span><span class="p">):</span>
        <span class="c1"># ========== train ========== #</span>
        <span class="n">train_loss</span> <span class="o">=</span> <span class="n">train_epoch</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="o">=</span><span class="n">train_dataloader</span><span class="p">,</span>
            <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span>
            <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">)</span>
        <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
        <span class="c1"># ========== validate ========== #</span>
        <span class="n">validate_loss</span> <span class="o">=</span> <span class="n">validate_epoch</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">validate_dataloader</span><span class="o">=</span><span class="n">validate_dataloader</span><span class="p">,</span>
            <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">)</span>
        <span class="n">validate_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">validate_loss</span><span class="p">)</span>

        <span class="c1"># 保存当前损失最低的模型</span>
        <span class="k">if</span> <span class="n">validate_loss</span> <span class="o">&lt;</span> <span class="n">best_val_loss</span><span class="p">:</span>
            <span class="n">best_val_loss</span> <span class="o">=</span> <span class="n">validate_loss</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;保存当前最好的模型，轮次为 epoch </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">model_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">save_model_path</span><span class="p">,</span> <span class="s1">&#39;min_loss_model_bj&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">model_path</span><span class="p">):</span>
                <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
            <span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">run</span><span class="p">():</span>
    <span class="c1"># 初始化配置参数</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">ParameterConfig</span><span class="p">()</span>

    <span class="c1"># 设置使用哪些显卡进行训练:默认为0</span>
    <span class="c1"># 如果你的电脑有大于1张的显卡，可以选择使用</span>
    <span class="c1"># nvidia-smi:查询当前显卡的状态：4090(16G显存), L40(48G显存), L20(24G显存), A100(80G), H100(80G), T4(16G), V100(16G)</span>
    <span class="c1"># os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &#39;0&#39;数字0代表你的第一张显卡</span>
    <span class="c1"># os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &#39;1&#39;数字1代表你的第二张显卡</span>
    <span class="c1"># os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] =&#39;0, 1&#39;代表同时利用0和1两张显卡</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;CUDA_VISIBLE_DEVICES&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;0&#39;</span>  <span class="c1"># 指定第一张显卡</span>

    <span class="c1"># 初始化tokenizer</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizerFast</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">vocab_path</span><span class="p">,</span>
                                  <span class="n">sep_token</span><span class="o">=</span><span class="s2">&quot;[SEP]&quot;</span><span class="p">,</span>
                                  <span class="n">pad_token</span><span class="o">=</span><span class="s2">&quot;[PAD]&quot;</span><span class="p">,</span>
                                  <span class="n">cls_token</span><span class="o">=</span><span class="s2">&quot;[CLS]&quot;</span><span class="p">)</span>

    <span class="c1"># 创建模型的输出目录</span>
    <span class="c1"># 如果没有创建会自动的创建输出目录</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">save_model_path</span><span class="p">):</span>
        <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">save_model_path</span><span class="p">)</span>

    <span class="c1"># 根据参数决定模型的创建方式</span>
    <span class="k">if</span> <span class="n">params</span><span class="o">.</span><span class="n">pretrained_model</span><span class="p">:</span>  <span class="c1"># 如果提供了预训练模型的路径</span>
        <span class="c1"># 加载预训练模型</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">GPT2LMHeadModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">pretrained_model</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># 如果没有提供预训练模型的路径</span>
        <span class="c1"># 从JSON文件中加载模型配置</span>
        <span class="n">model_config</span> <span class="o">=</span> <span class="n">GPT2Config</span><span class="o">.</span><span class="n">from_json_file</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">config_json</span><span class="p">)</span>
        <span class="c1"># print(model_config) 用于调试，查看模型配置</span>
        <span class="c1"># 根据配置初始化模型</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">GPT2LMHeadModel</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">model_config</span><span class="p">)</span>
    <span class="c1"># print(f&#39;model--&gt;{model}&#39;) 用于调试，查看模型结构</span>
    <span class="c1"># 将模型移动到指定的设备上（如GPU）</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="c1"># print(f&#39;model.config.vocab_size--&gt;{model.config.vocab_size}&#39;)</span>
    <span class="c1"># print(f&#39;tokenizer.vocab_size--&gt;{tokenizer.vocab_size}&#39;)</span>
    <span class="c1"># 确认模型的词汇表大小与分词器的词汇表大小一致</span>
    <span class="k">assert</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span>

    <span class="c1"># 初始化模型参数数量为0</span>
    <span class="n">num_parameters</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># 获取模型的所有参数</span>
    <span class="n">parameters</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span>
    <span class="c1"># 遍历每一项参数</span>
    <span class="k">for</span> <span class="n">parameter</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
        <span class="c1"># 将每一项参数的元素数量累加到总参数量中</span>
        <span class="n">num_parameters</span> <span class="o">+=</span> <span class="n">parameter</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
    <span class="c1"># 打印模型的总参数量</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;模型参数总量---》</span><span class="si">{</span><span class="n">num_parameters</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="c1"># 加载训练集和验证集</span>
    <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">validate_dataloader</span> <span class="o">=</span> <span class="n">get_dataloader</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">train_path</span><span class="p">,</span> <span class="n">params</span><span class="o">.</span><span class="n">valid_path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;train_dataloader--&gt;</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;validate_dataloader--&gt;</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">validate_dataloader</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">validate_dataloader</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">run</span><span class="p">()</span>
</code></pre></div>
<hr />
<ul>
<li>functions_tools.py代码解析</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>

<span class="k">def</span><span class="w"> </span><span class="nf">calculate_acc</span><span class="p">(</span><span class="n">logit</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=-</span><span class="mi">100</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    计算模型预测的准确token和总token。</span>
<span class="sd">    :param logit: 模型的预测输出</span>
<span class="sd">    :param labels: 数据的真实标签</span>
<span class="sd">    :param ignore_index: 指定一个索引，该索引对应的标签将被忽略，不会参与准确率的计算。默认值为-100。</span>
<span class="sd">    :return: n_correct: 预测正确的token个数。</span>
<span class="sd">    n_word: 非填充的总token个数。</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># 1.处理输入数据，去掉预测结果的最后一个字符，去掉标签的第一个字符</span>
    <span class="c1"># print(f&#39;logit---&gt;原始值的形状{logit.shape}&#39;)</span>
    <span class="c1"># print(f&#39;labels---&gt;原始值的形状{labels.shape}&#39;)</span>
    <span class="c1"># print(f&#39;logit.size--&gt;{logit.size(-1)}&#39;)</span>
    <span class="c1"># print(f&#39;logit[:, :-1, :]--&gt;{logit[:, :-1, :].shape}&#39;)</span>
    <span class="c1"># :-1-&gt;去掉预测的结束符</span>
    <span class="n">logit</span> <span class="o">=</span> <span class="n">logit</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">logit</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="c1"># print(f&#39;logit改变完形状的---&gt;{logit.shape}&#39;)</span>
    <span class="c1"># print(f&#39;labels[:, 1:]---&gt;{labels[:, 1:].shape}&#39;)</span>
    <span class="c1"># 1:-&gt;去掉标签的开始符, 实现错一位, logit和labels就能对应</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># print(f&#39;labels改变完形状的---&gt;{labels.shape}&#39;)</span>

    <span class="c1"># 2.取出最大概率值以及对应索引</span>
    <span class="n">max_index</span> <span class="o">=</span> <span class="n">logit</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># print(f&#39;logit取出模型预测最大索引值--&gt;{max_index}&#39;)</span>
    <span class="c1"># print(f&#39;max_index.shape--&gt;{max_index.shape}&#39;)</span>

    <span class="c1"># 3.计算预测正确的token个数和总的token个数</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    在 PyTorch 中，labels.ne(ignore_index) 表示将标签张量 labels 中的值不等于 ignore_index 的位置标记为 True，等于 ignore_index 的位置标记为 False。</span>
<span class="sd">    这个操作，以过滤掉 ignore_index 对损失的影响</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># 进行非运算，返回一个tensor，若labels的第i个位置为pad_id，则置为0，否则为1</span>
    <span class="n">non_pad_mask</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">ne</span><span class="p">(</span><span class="n">ignore_index</span><span class="p">)</span>
    <span class="c1"># print(f&#39;non_pad_mask--&gt;{non_pad_mask}&#39;)</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    在 PyTorch 中，logit.eq(labels) 表示将模型的预测输出值 max_index 中等于标签张量 labels 的位置标记为 True，</span>
<span class="sd">    不等于标签张量 labels 的位置标记为 False。以标记出预测输出值和标签值相等的位置。</span>
<span class="sd">    masked_select(non_pad_mask) 表示将张量中非填充标记的位置选出来。</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># print(f&#39;max_index.eq(labels)---&gt;{max_index.eq(labels).shape}&#39;)</span>
    <span class="c1"># print(f&#39;max_index.eq(labels)---&gt;{ max_index.eq(labels)}&#39;)</span>
    <span class="c1"># 计算预测正确的单词数量</span>
    <span class="n">n_correct</span> <span class="o">=</span> <span class="n">max_index</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">non_pad_mask</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="c1"># print(f&#39;n_correct--&gt;{n_correct}&#39;)</span>

    <span class="c1"># 计算非填充单词的总数</span>
    <span class="n">n_word</span> <span class="o">=</span> <span class="n">non_pad_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="c1"># print(f&#39;non_pad_mask.sum()--&gt;{non_pad_mask.sum()}&#39;)</span>

    <span class="k">return</span> <span class="n">n_correct</span><span class="p">,</span> <span class="n">n_word</span>
</code></pre></div>
<hr />
<h2 id="5">5. 模型预测（人机交互）<a class="headerlink" href="#5" title="Permanent link">&para;</a></h2>
<ul>
<li>使用训练好的模型，进行人机交互，输入Ctrl+Z结束对话之后，聊天记录将保存到sample目录下的sample.txt文件中。</li>
</ul>
<p>代码位置：llm_tuning/Gpt2_Chatbot/interact.py</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datetime</span><span class="w"> </span><span class="kn">import</span> <span class="n">datetime</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">GPT2LMHeadModel</span><span class="p">,</span> <span class="n">BertTokenizerFast</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">Gpt2_Chatbot.parameter_config</span><span class="w"> </span><span class="kn">import</span> <span class="n">ParameterConfig</span>


<span class="k">def</span><span class="w"> </span><span class="nf">top_k_top_p_filtering</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">filter_value</span><span class="o">=-</span><span class="nb">float</span><span class="p">(</span><span class="s1">&#39;Inf&#39;</span><span class="p">)):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    使用top-k和/或nucleus（top-p）筛选来过滤logits的分布</span>
<span class="sd">    :param logits: 最后一个token的logits的分布，形状为（词汇大小）</span>
<span class="sd">    :param top_k: top_k &gt; 0: 保留概率最高的top k个token（top-k筛选）</span>
<span class="sd">    :param top_p: top_p &gt; 0.0: 保留累积概率大于等于top_p的top token（nucleus筛选）</span>
<span class="sd">    :param filter_value: 极小值</span>
<span class="sd">    :return: logits: 过滤后的logits分布，其中低概率标记被设置为filter_value。</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># 确保logits的维度为1，这里只处理批量大小为1的情况。</span>
    <span class="k">assert</span> <span class="n">logits</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="c1"># 对top_k值进行安全性检查，防止它超过logits最后一个维度的大小，避免运行时错误。</span>
    <span class="n">top_k</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">top_k</span><span class="p">,</span> <span class="n">logits</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">top_k</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># 移除概率小于top_k标记</span>
        <span class="c1"># torch.topk()返回最后一维中最大的top_k个元素，返回值为二维(values, indices)</span>
        <span class="c1"># print(f&#39;torch.topk(logits, top_k)---&gt;{torch.topk(logits, top_k)}&#39;)</span>
        <span class="c1"># print(f&#39;torch.topk(logits, top_k)[0]--&gt;{torch.topk(logits, top_k)[0]}&#39;)</span>
        <span class="c1"># print(f&#39;torch.topk(logits, top_k)[0][-1]--&gt;{torch.topk(logits, top_k)[0][-1]}&#39;)</span>
        <span class="c1"># 判断logits的值，如果小于top_k标记，则设置为filter_value</span>
        <span class="n">indices_to_remove</span> <span class="o">=</span> <span class="n">logits</span> <span class="o">&lt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">top_k</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># print(f&#39;indices_to_remove---&gt;{indices_to_remove}&#39;)</span>
        <span class="c1"># print(f&#39;logits---&gt;{logits}&#39;)</span>
        <span class="n">logits</span><span class="p">[</span><span class="n">indices_to_remove</span><span class="p">]</span> <span class="o">=</span> <span class="n">filter_value</span>  <span class="c1"># 对于topk之外的其他元素的logits值设为负无穷</span>
        <span class="c1"># print(f&#39;logits---&gt;{logits}&#39;)</span>

    <span class="k">if</span> <span class="n">top_p</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
        <span class="n">sorted_logits</span><span class="p">,</span> <span class="n">sorted_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># 对logits进行递减排序</span>
        <span class="c1"># print(f&#39;sorted_logits--&gt;{sorted_logits}&#39;)</span>
        <span class="c1"># print(f&#39;sorted_indices--&gt;{sorted_indices}&#39;)</span>

        <span class="c1"># F.softmax(sorted_logits, dim=-1)：将排序后的 logits 转为概率分布</span>
        <span class="c1"># torch.cumsum(..., dim=-1)：计算累积概率</span>
        <span class="n">cumulative_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">sorted_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># 对应位置为 True 的 token 是 累积概率超过 top_p 阈值的 token，通常需要被移除</span>
        <span class="n">sorted_indices_to_remove</span> <span class="o">=</span> <span class="n">cumulative_probs</span> <span class="o">&gt;</span> <span class="n">top_p</span>
        <span class="c1"># 将索引向右移动，以确保即使第一个token超过阈值也能保留</span>
        <span class="n">sorted_indices_to_remove</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">=</span> <span class="n">sorted_indices_to_remove</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>  <span class="c1"># 将索引向右移动一位</span>
        <span class="n">sorted_indices_to_remove</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># 将第一个token设为False，确保第一个 token 被保留</span>
        <span class="c1"># print(f&#39;sorted_indices_to_remove---&gt;{sorted_indices_to_remove}&#39;)</span>

        <span class="c1"># 将需要移除的token设置为filter_value。</span>
        <span class="n">indices_to_remove</span> <span class="o">=</span> <span class="n">sorted_indices</span><span class="p">[</span><span class="n">sorted_indices_to_remove</span><span class="p">]</span>
        <span class="n">logits</span><span class="p">[</span><span class="n">indices_to_remove</span><span class="p">]</span> <span class="o">=</span> <span class="n">filter_value</span>
        <span class="c1"># print(f&#39;logits---&gt;{logits}&#39;)</span>
    <span class="k">return</span> <span class="n">logits</span>


<span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">():</span>
    <span class="c1"># 初始化参数配置对象</span>
    <span class="n">pconf</span> <span class="o">=</span> <span class="n">ParameterConfig</span><span class="p">()</span>

    <span class="c1"># 根据CUDA的可用性选择使用GPU还是CPU</span>
    <span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span>
    <span class="c1"># 打印当前使用的设备</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;using device:</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
    <span class="c1"># 设置环境变量以使用第一个GPU设备</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;CUDA_VISIBLE_DEVICES&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;0&#39;</span>

    <span class="c1"># 初始化BERT tokenizer，指定词汇表路径和特殊令牌</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizerFast</span><span class="p">(</span><span class="n">vocab_file</span><span class="o">=</span><span class="n">pconf</span><span class="o">.</span><span class="n">vocab_path</span><span class="p">,</span>
                                  <span class="n">sep_token</span><span class="o">=</span><span class="s2">&quot;[SEP]&quot;</span><span class="p">,</span>
                                  <span class="n">pad_token</span><span class="o">=</span><span class="s2">&quot;[PAD]&quot;</span><span class="p">,</span>
                                  <span class="n">cls_token</span><span class="o">=</span><span class="s2">&quot;[CLS]&quot;</span><span class="p">)</span>

    <span class="c1"># 从预训练路径加载GPT-2模型</span>
    <span class="n">model_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pconf</span><span class="o">.</span><span class="n">save_model_path</span><span class="p">,</span> <span class="s1">&#39;min_loss_model_bj&#39;</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">GPT2LMHeadModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="c1"># 将模型设置为评估模式</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="c1"># 如果配置了保存聊天记录的文件路径，则创建文件夹和文件以保存聊天记录</span>
    <span class="k">if</span> <span class="n">pconf</span><span class="o">.</span><span class="n">save_samples_path</span><span class="p">:</span>
        <span class="c1"># 检查路径是否存在，如果不存在则创建</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">pconf</span><span class="o">.</span><span class="n">save_samples_path</span><span class="p">):</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">pconf</span><span class="o">.</span><span class="n">save_samples_path</span><span class="p">)</span>
        <span class="c1"># 打开或创建一个名为&#39;samples.txt&#39;的文件，用于追加聊天记录</span>
        <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pconf</span><span class="o">.</span><span class="n">save_samples_path</span><span class="p">,</span> <span class="s1">&#39;samples.txt&#39;</span><span class="p">)</span>
        <span class="n">samples_file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf8&#39;</span><span class="p">)</span>
        <span class="c1"># 在文件中写入当前聊天记录的时间戳</span>
        <span class="n">samples_file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;聊天记录</span><span class="si">{}</span><span class="s2">:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()))</span>

    <span class="c1"># 初始化一个空列表用于存储聊天记录，聊天记录以token id的形式存储</span>
    <span class="n">history</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># 打印欢迎语，介绍聊天机器人的身份</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;你好，我是您的健康助手&#39;</span><span class="p">)</span>

    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># 提示用户输入文本并存储</span>
            <span class="n">text</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s2">&quot;user:&quot;</span><span class="p">)</span>
            <span class="c1"># print(f&#39;text---&gt;{text}&#39;)</span>
            <span class="c1"># 如果配置了保存样本的路径，则将用户输入的文本写入样本文件</span>
            <span class="k">if</span> <span class="n">pconf</span><span class="o">.</span><span class="n">save_samples_path</span><span class="p">:</span>
                <span class="n">samples_file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;user:</span><span class="si">{}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>

            <span class="c1"># 使用tokenizer将用户输入的文本转换为文本ID序列，不添加特殊令牌</span>
            <span class="n">text_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;用户问题：&quot;</span> <span class="o">+</span> <span class="n">text</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;text_ids--&gt;</span><span class="si">{</span><span class="n">text_ids</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="c1"># 将文本ID序列添加到历史对话列表中</span>
            <span class="n">history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text_ids</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;history--&gt;</span><span class="si">{</span><span class="n">history</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

            <span class="c1"># 初始化输入ID序列，每个输入以[CLS]令牌开始</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">cls_token_id</span><span class="p">]</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;input_ids--&gt;</span><span class="si">{</span><span class="n">input_ids</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

            <span class="c1"># pconf.max_history_len目的：将最近的历史消息记录送到模型</span>
            <span class="c1"># 遍历历史记录，history_id用于记录索引，history_utr用于记录每个历史对话的token ID列表</span>
            <span class="c1"># eg：history =  [[872, 1962], [872, 1962], [872, 342, 123], [334, 55,234]]--&gt;history[-3:]</span>
            <span class="k">for</span> <span class="n">history_id</span><span class="p">,</span> <span class="n">history_utr</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="o">-</span><span class="n">pconf</span><span class="o">.</span><span class="n">max_history_len</span><span class="p">:]):</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;history_utr---&gt;</span><span class="si">{</span><span class="n">history_utr</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
                <span class="c1"># 将历史对话的token ID列表添加到input_ids中</span>
                <span class="n">input_ids</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">history_utr</span><span class="p">)</span>
                <span class="c1"># 在每个历史对话的token ID列表之后添加分隔符token ID</span>
                <span class="n">input_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">sep_token_id</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;input_ids---&gt;</span><span class="si">{</span><span class="n">input_ids</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;存储了历史对话的输入信息--&gt;</span><span class="si">{</span><span class="n">input_ids</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
            <span class="c1"># 将input_ids扩展为二维张量，形状为（1，input_ids长度）</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;符合模型的输入--&gt;</span><span class="si">{</span><span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

            <span class="c1"># 初始化一个空列表response，用于存储生成的响应</span>
            <span class="n">response</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># 根据context，生成的response</span>
            <span class="c1"># 循环生成响应，次数由pconf.max_len决定</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">pconf</span><span class="o">.</span><span class="n">max_len</span><span class="p">):</span>
                <span class="c1"># 使用模型生成输出</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">)</span>
                <span class="c1"># 获取模型输出的logits，即未经过softmax的预测值</span>
                <span class="n">logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">logits</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;logits---&gt;</span><span class="si">{</span><span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
                <span class="c1"># 从logits中提取下一个token的概率值</span>
                <span class="n">next_token_logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;next_token_logits----&gt;</span><span class="si">{</span><span class="n">next_token_logits</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

                <span class="c1"># 对于已生成的结果generated中的每个token添加一个重复惩罚项, 降低其生成概率(解决复读机问题)</span>
                <span class="c1"># print(f&#39;set(response)--&gt;{set(response)}&#39;)</span>
                <span class="c1"># 遍历响应中的每个标识符，以应用重复惩罚</span>
                <span class="k">for</span> <span class="nb">id</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">response</span><span class="p">):</span>
                    <span class="c1"># print(f&#39;id---&gt;{id}&#39;)</span>
                    <span class="c1"># 根据重复惩罚配置，调整标识符的下一次出现的logits值</span>
                    <span class="k">if</span> <span class="n">next_token_logits</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">next_token_logits</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">*=</span> <span class="n">pconf</span><span class="o">.</span><span class="n">repetition_penalty</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">next_token_logits</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">/=</span> <span class="n">pconf</span><span class="o">.</span><span class="n">repetition_penalty</span>

                <span class="c1"># 对于[UNK]的概率设为无穷小，也就是说模型的预测结果不可能是[UNK]这个token</span>
                <span class="n">next_token_logits</span><span class="p">[</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="s1">&#39;[UNK]&#39;</span><span class="p">)]</span> <span class="o">=</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s1">&#39;Inf&#39;</span><span class="p">)</span>

                <span class="c1"># 这里使用了 top_k_top_p_filtering 函数，该函数的作用是根据给定的 top_k 参数和 top_p 参数，将不符合的token概率被设置为无穷小，从而选择出符合 k 个元素的下标和对应的值</span>
                <span class="c1"># 这种方法可以在保证生成文本的质量的同时，具有一定的随机性</span>
                <span class="n">filtered_logits</span> <span class="o">=</span> <span class="n">top_k_top_p_filtering</span><span class="p">(</span><span class="n">next_token_logits</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="n">pconf</span><span class="o">.</span><span class="n">topk</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="n">pconf</span><span class="o">.</span><span class="n">topp</span><span class="p">)</span>

                <span class="c1"># torch.multinomial表示从候选集合中无放回地进行抽取num_samples个元素，权重越高，抽到的几率越高，返回元素的下标</span>
                <span class="n">next_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">filtered_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="c1"># print(f&#39;next_token--&gt;{next_token}&#39;)</span>

                <span class="c1"># 遇到[SEP]则表明response生成结束</span>
                <span class="k">if</span> <span class="n">next_token</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">sep_token_id</span><span class="p">:</span>
                    <span class="k">break</span>
                <span class="c1"># 将预测的下一个token的ID添加到响应序列中</span>
                <span class="n">response</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">next_token</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;response--&gt;</span><span class="si">{</span><span class="n">response</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>


                <span class="c1"># 在输入ID序列中添加下一个token的ID，以便将其作为下一个预测步骤的输入</span>
                <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">next_token</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

            <span class="n">model_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;模型回答：&quot;</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="c1"># print(f&#39;model_ids + response---&gt;{model_ids + response}&#39;)</span>
            <span class="c1"># 将机器人的响应添加到对话历史中</span>
            <span class="n">history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model_ids</span> <span class="o">+</span> <span class="n">response</span><span class="p">)</span>

            <span class="c1"># 将响应从ID序列转换为文本</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
            <span class="c1"># 打印机器人的回复</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;chatbot:&quot;</span> <span class="o">+</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>
        <span class="k">except</span> <span class="ne">KeyboardInterrupt</span><span class="p">:</span>
            <span class="k">break</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</code></pre></div>
<h2 id="6-flaskweb">6. 基于Flask框架web开发(了解)<a class="headerlink" href="#6-flaskweb" title="Permanent link">&para;</a></h2>
<ul>
<li>对interact.py进行调整, 去除while无限循环，由前端保存history，只需要对传入的句子进行预测即可。</li>
</ul>
<p>代码位置：llm_tuning/Gpt2_Chatbot/flask_predict.py</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">GPT2LMHeadModel</span><span class="p">,</span> <span class="n">BertTokenizerFast</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">Gpt2_Chatbot.interact</span><span class="w"> </span><span class="kn">import</span> <span class="n">top_k_top_p_filtering</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">Gpt2_Chatbot.parameter_config</span><span class="w"> </span><span class="kn">import</span> <span class="n">ParameterConfig</span>

<span class="c1"># 初始化参数配置对象</span>
<span class="n">pconf</span> <span class="o">=</span> <span class="n">ParameterConfig</span><span class="p">()</span>
<span class="c1"># 根据CUDA的可用性选择使用GPU还是CPU</span>
<span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span>
<span class="c1"># 打印当前使用的设备</span>
<span class="c1"># print(&#39;using device:{}&#39;.format(device))</span>
<span class="c1"># 设置环境变量以使用第一个GPU设备</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;CUDA_VISIBLE_DEVICES&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;0&#39;</span>

<span class="c1"># 初始化BERT tokenizer，指定词汇表路径和特殊令牌</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizerFast</span><span class="p">(</span><span class="n">vocab_file</span><span class="o">=</span><span class="n">pconf</span><span class="o">.</span><span class="n">vocab_path</span><span class="p">,</span>
                              <span class="n">sep_token</span><span class="o">=</span><span class="s2">&quot;[SEP]&quot;</span><span class="p">,</span>
                              <span class="n">pad_token</span><span class="o">=</span><span class="s2">&quot;[PAD]&quot;</span><span class="p">,</span>
                              <span class="n">cls_token</span><span class="o">=</span><span class="s2">&quot;[CLS]&quot;</span><span class="p">)</span>

<span class="c1"># 从预训练路径加载GPT-2模型</span>
<span class="n">model_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pconf</span><span class="o">.</span><span class="n">save_model_path</span><span class="p">,</span> <span class="s1">&#39;min_loss_model_bj&#39;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GPT2LMHeadModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="c1"># 将模型设置为评估模式</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>


<span class="c1"># 模型预测函数，输入为用户输入的文本，返回预测结果</span>
<span class="k">def</span><span class="w"> </span><span class="nf">model_predict</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">history</span><span class="p">):</span>
    <span class="c1"># 使用tokenizer将用户输入的文本转换为文本ID序列，不添加特殊令牌</span>
    <span class="n">text_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;用户问题：&quot;</span> <span class="o">+</span> <span class="n">text</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="c1"># print(f&#39;text_ids--&gt;{text_ids}&#39;)</span>
    <span class="c1"># 将文本ID序列添加到历史对话列表中</span>
    <span class="n">history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text_ids</span><span class="p">)</span>
    <span class="c1"># print(f&#39;history--&gt;{history}&#39;)</span>

    <span class="c1"># 初始化输入ID序列，每个输入以[CLS]令牌开始</span>
    <span class="n">input_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">cls_token_id</span><span class="p">]</span>
    <span class="c1"># print(f&#39;input_ids--&gt;{input_ids}&#39;)</span>

    <span class="c1"># pconf.max_history_len目的：将最近的历史消息记录送到模型</span>
    <span class="c1"># 遍历历史记录，history_id用于记录索引，history_utr用于记录每个历史对话的token ID列表</span>
    <span class="c1"># eg：history =  [[872, 1962], [872, 1962], [872, 342, 123], [334, 55,234]]--&gt;history[-3:]</span>
    <span class="k">for</span> <span class="n">history_id</span><span class="p">,</span> <span class="n">history_utr</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="o">-</span><span class="n">pconf</span><span class="o">.</span><span class="n">max_history_len</span><span class="p">:]):</span>
        <span class="c1"># print(f&#39;history_utr---&gt;{history_utr}&#39;)</span>
        <span class="c1"># 将历史对话的token ID列表添加到input_ids中</span>
        <span class="n">input_ids</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">history_utr</span><span class="p">)</span>
        <span class="c1"># 在每个历史对话的token ID列表之后添加分隔符token ID</span>
        <span class="n">input_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">sep_token_id</span><span class="p">)</span>
        <span class="c1"># print(f&#39;input_ids---&gt;{input_ids}&#39;)</span>
    <span class="c1"># print(f&#39;存储了历史对话的输入信息--&gt;{input_ids}&#39;)</span>

    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="c1"># 将input_ids扩展为二维张量，形状为（1，input_ids长度）</span>
    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># print(f&#39;符合模型的输入--&gt;{input_ids.shape}&#39;)</span>

    <span class="c1"># 初始化一个空列表response，用于存储生成的响应</span>
    <span class="n">response</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># 根据context，生成的response</span>
    <span class="c1"># 循环生成响应，次数由pconf.max_len决定</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">pconf</span><span class="o">.</span><span class="n">max_len</span><span class="p">):</span>
        <span class="c1"># 使用模型生成输出</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">)</span>
        <span class="c1"># 获取模型输出的logits，即未经过softmax的预测值</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">logits</span>
        <span class="c1"># print(f&#39;logits---&gt;{logits.shape}&#39;)</span>
        <span class="c1"># 从logits中提取下一个token的概率值</span>
        <span class="n">next_token_logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
        <span class="c1"># print(f&#39;next_token_logits----&gt;{next_token_logits.shape}&#39;)</span>

        <span class="c1"># 对于已生成的结果generated中的每个token添加一个重复惩罚项, 降低其生成概率(解决复读机问题)</span>
        <span class="c1"># print(f&#39;set(response)--&gt;{set(response)}&#39;)</span>
        <span class="c1"># 遍历响应中的每个标识符，以应用重复惩罚</span>
        <span class="k">for</span> <span class="nb">id</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">response</span><span class="p">):</span>
            <span class="c1"># print(f&#39;id---&gt;{id}&#39;)</span>
            <span class="c1"># 根据重复惩罚配置，调整标识符的下一次出现的logits值</span>
            <span class="k">if</span> <span class="n">next_token_logits</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">next_token_logits</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">*=</span> <span class="n">pconf</span><span class="o">.</span><span class="n">repetition_penalty</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">next_token_logits</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">/=</span> <span class="n">pconf</span><span class="o">.</span><span class="n">repetition_penalty</span>

        <span class="c1"># 对于[UNK]的概率设为无穷小，也就是说模型的预测结果不可能是[UNK]这个token</span>
        <span class="n">next_token_logits</span><span class="p">[</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="s1">&#39;[UNK]&#39;</span><span class="p">)]</span> <span class="o">=</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s1">&#39;Inf&#39;</span><span class="p">)</span>

        <span class="c1"># 这里使用了 top_k_top_p_filtering 函数，该函数的作用是根据给定的 top_k 参数和 top_p 参数，将不符合的token概率被设置为无穷小，从而选择出符合 k 个元素的下标和对应的值</span>
        <span class="c1"># 这种方法可以在保证生成文本的质量的同时，具有一定的随机性</span>
        <span class="n">filtered_logits</span> <span class="o">=</span> <span class="n">top_k_top_p_filtering</span><span class="p">(</span><span class="n">next_token_logits</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="n">pconf</span><span class="o">.</span><span class="n">topk</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="n">pconf</span><span class="o">.</span><span class="n">topp</span><span class="p">)</span>

        <span class="c1"># torch.multinomial表示从候选集合中无放回地进行抽取num_samples个元素，权重越高，抽到的几率越高，返回元素的下标</span>
        <span class="n">next_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">filtered_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># print(f&#39;next_token--&gt;{next_token}&#39;)</span>

        <span class="c1"># 遇到[SEP]则表明response生成结束</span>
        <span class="k">if</span> <span class="n">next_token</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">sep_token_id</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="c1"># 将预测的下一个token的ID添加到响应序列中</span>
        <span class="n">response</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">next_token</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="c1"># print(f&#39;response--&gt;{response}&#39;)</span>

        <span class="c1"># 在输入ID序列中添加下一个token的ID，以便将其作为下一个预测步骤的输入</span>
        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">next_token</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">model_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;模型回答：&quot;</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="c1"># print(f&#39;model_ids + response---&gt;{model_ids + response}&#39;)</span>
    <span class="c1"># 将机器人的响应添加到对话历史中</span>
    <span class="n">history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model_ids</span> <span class="o">+</span> <span class="n">response</span><span class="p">)</span>

    <span class="c1"># 将响应从ID序列转换为文本</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
    <span class="c1"># 打印机器人的回复</span>
    <span class="n">response</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="p">,</span> <span class="n">history</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">history</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">response</span><span class="p">,</span> <span class="n">history</span> <span class="o">=</span> <span class="n">model_predict</span><span class="p">(</span><span class="s1">&#39;你好&#39;</span><span class="p">,</span> <span class="n">history</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;response---&gt;</span><span class="si">{</span><span class="n">response</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;history---&gt;</span><span class="si">{</span><span class="n">history</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">response</span><span class="p">,</span> <span class="n">history</span> <span class="o">=</span> <span class="n">model_predict</span><span class="p">(</span><span class="s1">&#39;卵巢癌肉瘤的影像学检查有些什么&#39;</span><span class="p">,</span> <span class="n">history</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;response---&gt;</span><span class="si">{</span><span class="n">response</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;history---&gt;</span><span class="si">{</span><span class="n">history</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div>
<ul>
<li>基于Flask框架的web后端接口</li>
</ul>
<p>这部分可以用大模型生成，写好提示词即可。</p>
<div class="highlight"><pre><span></span><code><span class="na">使用大模型生成web前后端代码,</span><span class="w"> </span><span class="s">描述如下:</span>
<span class="na">现在你是一个代码专家,</span><span class="w"> </span><span class="s">目前已经训练好了一个模型, 并且已经将该模型进行了封装, 函数名为model_predict(), 该函数传入参数为text, history，其中text为用户问题，history为一个列表，用来保存上下文信息；返回值为response, history，其中response为预测结果，history为列表。</span>

<span class="na">现在需要你基于Flask框架,</span><span class="w"> </span><span class="s">对该函数进行API接口封装制作, 并且希望能够制作一个简单的web界面, 界面的主要功能呈现如下:</span>
<span class="na">1.</span><span class="w"> </span><span class="s">用户输入问题和history列表, 然后返回预测结果和history。这个history不需要前端往里边添加内容，只需要保存这个变量即可。在前端页面刷新时，这个变量清空为[]。</span>
<span class="na">2.</span><span class="w"> </span><span class="s">将用户和模型的聊天信息保留在页面上展示</span>
<span class="na">3.</span><span class="w"> </span><span class="s">页面标题名称叫做:黑马医疗问诊机器人</span>
<span class="na">4.</span><span class="w"> </span><span class="s">页面标题和输入对话框布局要对称, 并且用不同的颜色渲染</span>
<span class="na">请给出详细的app.py和index.html的代码</span>
</code></pre></div>
<p>代码位置：llm_tuning/Gpt2_Chatbot/app.py</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">flask</span><span class="w"> </span><span class="kn">import</span> <span class="n">Flask</span><span class="p">,</span> <span class="n">request</span><span class="p">,</span> <span class="n">jsonify</span><span class="p">,</span> <span class="n">render_template</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">Gpt2_Chatbot.flask_predict</span><span class="w"> </span><span class="kn">import</span> <span class="n">model_predict</span>

<span class="n">app</span> <span class="o">=</span> <span class="n">Flask</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

<span class="c1"># API 接口</span>
<span class="nd">@app</span><span class="o">.</span><span class="n">route</span><span class="p">(</span><span class="s1">&#39;/api/predict&#39;</span><span class="p">,</span> <span class="n">methods</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;POST&#39;</span><span class="p">])</span>
<span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">():</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">request</span><span class="o">.</span><span class="n">json</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="n">question</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;question&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Question--&gt;</span><span class="si">{</span><span class="n">question</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="c1"># 前端传过来一个 history 列表（例如：[[872, 1962], [872, 1962, 8024, 6821...]]）</span>
    <span class="n">history</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;history&#39;</span><span class="p">,</span> <span class="p">[])</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;History--&gt;</span><span class="si">{</span><span class="n">history</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="c1"># 调用模型预测，假设 model_predict 返回 (answer, new_history)</span>
    <span class="n">answer</span><span class="p">,</span> <span class="n">new_history</span> <span class="o">=</span> <span class="n">model_predict</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">history</span><span class="o">=</span><span class="n">history</span><span class="p">)</span>

    <span class="c1"># 把 answer 和更新后的 history 一并返回（前端保存并更新history，企业中也可以将history其保存到数据库或文件中）</span>
    <span class="k">return</span> <span class="n">jsonify</span><span class="p">({</span><span class="s1">&#39;question&#39;</span><span class="p">:</span> <span class="n">question</span><span class="p">,</span> <span class="s1">&#39;answer&#39;</span><span class="p">:</span> <span class="n">answer</span><span class="p">,</span> <span class="s1">&#39;history&#39;</span><span class="p">:</span> <span class="n">new_history</span><span class="p">})</span>

<span class="c1"># Web 界面</span>
<span class="nd">@app</span><span class="o">.</span><span class="n">route</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">index</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">render_template</span><span class="p">(</span><span class="s1">&#39;index.html&#39;</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">app</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">debug</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
<ul>
<li>web前端代码</li>
</ul>
<p>代码位置：llm_tuning/Gpt2_Chatbot/templates/index.html</p>
<div class="highlight"><pre><span></span><code><span class="cp">&lt;!DOCTYPE html&gt;</span>
<span class="p">&lt;</span><span class="nt">html</span> <span class="na">lang</span><span class="o">=</span><span class="s">&quot;zh-CN&quot;</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">head</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">meta</span> <span class="na">charset</span><span class="o">=</span><span class="s">&quot;UTF-8&quot;</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">meta</span> <span class="na">name</span><span class="o">=</span><span class="s">&quot;viewport&quot;</span> <span class="na">content</span><span class="o">=</span><span class="s">&quot;width=device-width, initial-scale=1.0&quot;</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">title</span><span class="p">&gt;</span>黑马医疗问诊机器人<span class="p">&lt;/</span><span class="nt">title</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">style</span><span class="p">&gt;</span>
<span class="w">        </span><span class="nt">body</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="k">font-family</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;Arial&#39;</span><span class="p">,</span><span class="w"> </span><span class="kc">sans-serif</span><span class="p">;</span>
<span class="w">            </span><span class="k">max-width</span><span class="p">:</span><span class="w"> </span><span class="mi">800</span><span class="kt">px</span><span class="p">;</span>
<span class="w">            </span><span class="k">margin</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="kc">auto</span><span class="p">;</span>
<span class="w">            </span><span class="k">padding</span><span class="p">:</span><span class="w"> </span><span class="mi">20</span><span class="kt">px</span><span class="p">;</span>
<span class="w">            </span><span class="k">background-color</span><span class="p">:</span><span class="w"> </span><span class="mh">#f5f5f5</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="p">.</span><span class="nc">header</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="k">text-align</span><span class="p">:</span><span class="w"> </span><span class="kc">center</span><span class="p">;</span>
<span class="w">            </span><span class="k">margin-bottom</span><span class="p">:</span><span class="w"> </span><span class="mi">30</span><span class="kt">px</span><span class="p">;</span>
<span class="w">            </span><span class="k">padding</span><span class="p">:</span><span class="w"> </span><span class="mi">20</span><span class="kt">px</span><span class="p">;</span>
<span class="w">            </span><span class="k">background</span><span class="p">:</span><span class="w"> </span><span class="nb">linear-gradient</span><span class="p">(</span><span class="mi">135</span><span class="kt">deg</span><span class="p">,</span><span class="w"> </span><span class="mh">#4b6cb7</span><span class="p">,</span><span class="w"> </span><span class="mh">#182848</span><span class="p">);</span>
<span class="w">            </span><span class="k">color</span><span class="p">:</span><span class="w"> </span><span class="kc">white</span><span class="p">;</span>
<span class="w">            </span><span class="k">border-radius</span><span class="p">:</span><span class="w"> </span><span class="mi">10</span><span class="kt">px</span><span class="p">;</span>
<span class="w">            </span><span class="k">box-shadow</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="mi">4</span><span class="kt">px</span><span class="w"> </span><span class="mi">8</span><span class="kt">px</span><span class="w"> </span><span class="nb">rgba</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mf">0.1</span><span class="p">);</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="p">.</span><span class="nc">chat-container</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="k">background-color</span><span class="p">:</span><span class="w"> </span><span class="kc">white</span><span class="p">;</span>
<span class="w">            </span><span class="k">border-radius</span><span class="p">:</span><span class="w"> </span><span class="mi">10</span><span class="kt">px</span><span class="p">;</span>
<span class="w">            </span><span class="k">box-shadow</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="mi">4</span><span class="kt">px</span><span class="w"> </span><span class="mi">8</span><span class="kt">px</span><span class="w"> </span><span class="nb">rgba</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mf">0.1</span><span class="p">);</span>
<span class="w">            </span><span class="k">padding</span><span class="p">:</span><span class="w"> </span><span class="mi">20</span><span class="kt">px</span><span class="p">;</span>
<span class="w">            </span><span class="k">margin-bottom</span><span class="p">:</span><span class="w"> </span><span class="mi">20</span><span class="kt">px</span><span class="p">;</span>
<span class="w">            </span><span class="k">height</span><span class="p">:</span><span class="w"> </span><span class="mi">400</span><span class="kt">px</span><span class="p">;</span>
<span class="w">            </span><span class="k">overflow-y</span><span class="p">:</span><span class="w"> </span><span class="kc">auto</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="p">.</span><span class="nc">message</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="k">margin-bottom</span><span class="p">:</span><span class="w"> </span><span class="mi">15</span><span class="kt">px</span><span class="p">;</span>
<span class="w">            </span><span class="k">padding</span><span class="p">:</span><span class="w"> </span><span class="mi">10</span><span class="kt">px</span><span class="w"> </span><span class="mi">15</span><span class="kt">px</span><span class="p">;</span>
<span class="w">            </span><span class="k">border-radius</span><span class="p">:</span><span class="w"> </span><span class="mi">18</span><span class="kt">px</span><span class="p">;</span>
<span class="w">            </span><span class="k">max-width</span><span class="p">:</span><span class="w"> </span><span class="mi">70</span><span class="kt">%</span><span class="p">;</span>
<span class="w">            </span><span class="k">word-wrap</span><span class="p">:</span><span class="w"> </span><span class="kc">break-word</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="p">.</span><span class="nc">user-message</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="k">background-color</span><span class="p">:</span><span class="w"> </span><span class="mh">#e3f2fd</span><span class="p">;</span>
<span class="w">            </span><span class="k">margin-left</span><span class="p">:</span><span class="w"> </span><span class="kc">auto</span><span class="p">;</span>
<span class="w">            </span><span class="k">border-bottom-right-radius</span><span class="p">:</span><span class="w"> </span><span class="mi">5</span><span class="kt">px</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="p">.</span><span class="nc">bot-message</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="k">background-color</span><span class="p">:</span><span class="w"> </span><span class="mh">#f1f1f1</span><span class="p">;</span>
<span class="w">            </span><span class="k">margin-right</span><span class="p">:</span><span class="w"> </span><span class="kc">auto</span><span class="p">;</span>
<span class="w">            </span><span class="k">border-bottom-left-radius</span><span class="p">:</span><span class="w"> </span><span class="mi">5</span><span class="kt">px</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="p">.</span><span class="nc">input-container</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="k">display</span><span class="p">:</span><span class="w"> </span><span class="kc">flex</span><span class="p">;</span>
<span class="w">            </span><span class="k">gap</span><span class="p">:</span><span class="w"> </span><span class="mi">10</span><span class="kt">px</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="p">#</span><span class="nn">user-input</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="k">flex</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">            </span><span class="k">padding</span><span class="p">:</span><span class="w"> </span><span class="mi">12</span><span class="kt">px</span><span class="p">;</span>
<span class="w">            </span><span class="k">border</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="kt">px</span><span class="w"> </span><span class="kc">solid</span><span class="w"> </span><span class="mh">#ddd</span><span class="p">;</span>
<span class="w">            </span><span class="k">border-radius</span><span class="p">:</span><span class="w"> </span><span class="mi">20</span><span class="kt">px</span><span class="p">;</span>
<span class="w">            </span><span class="k">font-size</span><span class="p">:</span><span class="w"> </span><span class="mi">16</span><span class="kt">px</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="p">#</span><span class="nn">send-button</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="k">padding</span><span class="p">:</span><span class="w"> </span><span class="mi">12</span><span class="kt">px</span><span class="w"> </span><span class="mi">20</span><span class="kt">px</span><span class="p">;</span>
<span class="w">            </span><span class="k">background-color</span><span class="p">:</span><span class="w"> </span><span class="mh">#4b6cb7</span><span class="p">;</span>
<span class="w">            </span><span class="k">color</span><span class="p">:</span><span class="w"> </span><span class="kc">white</span><span class="p">;</span>
<span class="w">            </span><span class="k">border</span><span class="p">:</span><span class="w"> </span><span class="kc">none</span><span class="p">;</span>
<span class="w">            </span><span class="k">border-radius</span><span class="p">:</span><span class="w"> </span><span class="mi">20</span><span class="kt">px</span><span class="p">;</span>
<span class="w">            </span><span class="k">cursor</span><span class="p">:</span><span class="w"> </span><span class="kc">pointer</span><span class="p">;</span>
<span class="w">            </span><span class="k">font-size</span><span class="p">:</span><span class="w"> </span><span class="mi">16</span><span class="kt">px</span><span class="p">;</span>
<span class="w">            </span><span class="k">transition</span><span class="p">:</span><span class="w"> </span><span class="k">background-color</span><span class="w"> </span><span class="mf">0.3</span><span class="kt">s</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="p">#</span><span class="nn">send-button</span><span class="p">:</span><span class="nd">hover</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="k">background-color</span><span class="p">:</span><span class="w"> </span><span class="mh">#3a56a1</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="p">.</span><span class="nc">timestamp</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="k">font-size</span><span class="p">:</span><span class="w"> </span><span class="mi">12</span><span class="kt">px</span><span class="p">;</span>
<span class="w">            </span><span class="k">color</span><span class="p">:</span><span class="w"> </span><span class="mh">#777</span><span class="p">;</span>
<span class="w">            </span><span class="k">margin-top</span><span class="p">:</span><span class="w"> </span><span class="mi">5</span><span class="kt">px</span><span class="p">;</span>
<span class="w">            </span><span class="k">text-align</span><span class="p">:</span><span class="w"> </span><span class="kc">right</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">&lt;/</span><span class="nt">style</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">head</span><span class="p">&gt;</span>
<span class="p">&lt;</span><span class="nt">body</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">div</span> <span class="na">class</span><span class="o">=</span><span class="s">&quot;header&quot;</span><span class="p">&gt;</span>
        <span class="p">&lt;</span><span class="nt">h1</span><span class="p">&gt;</span>黑马医疗问诊机器人<span class="p">&lt;/</span><span class="nt">h1</span><span class="p">&gt;</span>
        <span class="p">&lt;</span><span class="nt">p</span><span class="p">&gt;</span>您的智能健康顾问<span class="p">&lt;/</span><span class="nt">p</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">div</span><span class="p">&gt;</span>

    <span class="p">&lt;</span><span class="nt">div</span> <span class="na">class</span><span class="o">=</span><span class="s">&quot;chat-container&quot;</span> <span class="na">id</span><span class="o">=</span><span class="s">&quot;chat-box&quot;</span><span class="p">&gt;</span>
        <span class="cm">&lt;!-- 初始系统消息 --&gt;</span>
        <span class="p">&lt;</span><span class="nt">div</span> <span class="na">class</span><span class="o">=</span><span class="s">&quot;message bot-message&quot;</span><span class="p">&gt;</span>
            您好！我是黑马小健康助手，请问有什么健康问题可以帮您解答？
            <span class="p">&lt;</span><span class="nt">div</span> <span class="na">class</span><span class="o">=</span><span class="s">&quot;timestamp&quot;</span><span class="p">&gt;</span>系统消息<span class="p">&lt;/</span><span class="nt">div</span><span class="p">&gt;</span>
        <span class="p">&lt;/</span><span class="nt">div</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">div</span><span class="p">&gt;</span>

    <span class="p">&lt;</span><span class="nt">div</span> <span class="na">class</span><span class="o">=</span><span class="s">&quot;input-container&quot;</span><span class="p">&gt;</span>
        <span class="p">&lt;</span><span class="nt">input</span> <span class="na">type</span><span class="o">=</span><span class="s">&quot;text&quot;</span> <span class="na">id</span><span class="o">=</span><span class="s">&quot;user-input&quot;</span> <span class="na">placeholder</span><span class="o">=</span><span class="s">&quot;请输入您的健康问题...&quot;</span> <span class="na">autofocus</span><span class="p">&gt;</span>
        <span class="p">&lt;</span><span class="nt">button</span> <span class="na">id</span><span class="o">=</span><span class="s">&quot;send-button&quot;</span><span class="p">&gt;</span>发送<span class="p">&lt;/</span><span class="nt">button</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">div</span><span class="p">&gt;</span>

<span class="p">&lt;</span><span class="nt">script</span><span class="p">&gt;</span>
<span class="w">    </span><span class="c1">// 每次刷新页面 history 都从空开始</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="nx">history</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[];</span>

<span class="w">    </span><span class="nb">document</span><span class="p">.</span><span class="nx">getElementById</span><span class="p">(</span><span class="s1">&#39;send-button&#39;</span><span class="p">).</span><span class="nx">addEventListener</span><span class="p">(</span><span class="s1">&#39;click&#39;</span><span class="p">,</span><span class="w"> </span><span class="nx">sendMessage</span><span class="p">);</span>
<span class="w">    </span><span class="nb">document</span><span class="p">.</span><span class="nx">getElementById</span><span class="p">(</span><span class="s1">&#39;user-input&#39;</span><span class="p">).</span><span class="nx">addEventListener</span><span class="p">(</span><span class="s1">&#39;keypress&#39;</span><span class="p">,</span><span class="w"> </span><span class="kd">function</span><span class="p">(</span><span class="nx">e</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nx">e</span><span class="p">.</span><span class="nx">key</span><span class="w"> </span><span class="o">===</span><span class="w"> </span><span class="s1">&#39;Enter&#39;</span><span class="p">)</span><span class="w"> </span><span class="nx">sendMessage</span><span class="p">();</span>
<span class="w">    </span><span class="p">});</span>

<span class="w">    </span><span class="kd">function</span><span class="w"> </span><span class="nx">sendMessage</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kd">const</span><span class="w"> </span><span class="nx">userInput</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">document</span><span class="p">.</span><span class="nx">getElementById</span><span class="p">(</span><span class="s1">&#39;user-input&#39;</span><span class="p">);</span>
<span class="w">        </span><span class="kd">const</span><span class="w"> </span><span class="nx">question</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">userInput</span><span class="p">.</span><span class="nx">value</span><span class="p">.</span><span class="nx">trim</span><span class="p">();</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nx">question</span><span class="w"> </span><span class="o">===</span><span class="w"> </span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="w"> </span><span class="k">return</span><span class="p">;</span>

<span class="w">        </span><span class="c1">// 显示用户消息</span>
<span class="w">        </span><span class="nx">addMessage</span><span class="p">(</span><span class="nx">question</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;user&#39;</span><span class="p">);</span>
<span class="w">        </span><span class="nx">userInput</span><span class="p">.</span><span class="nx">value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;&#39;</span><span class="p">;</span>

<span class="w">        </span><span class="c1">// 把当前 history 发给后端</span>
<span class="w">        </span><span class="nx">fetch</span><span class="p">(</span><span class="s1">&#39;/api/predict&#39;</span><span class="p">,</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nx">method</span><span class="o">:</span><span class="w"> </span><span class="s1">&#39;POST&#39;</span><span class="p">,</span>
<span class="w">            </span><span class="nx">headers</span><span class="o">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="s1">&#39;Content-Type&#39;</span><span class="o">:</span><span class="w"> </span><span class="s1">&#39;application/json&#39;</span><span class="w"> </span><span class="p">},</span>
<span class="w">            </span><span class="nx">body</span><span class="o">:</span><span class="w"> </span><span class="nb">JSON</span><span class="p">.</span><span class="nx">stringify</span><span class="p">({</span><span class="w"> </span><span class="nx">question</span><span class="o">:</span><span class="w"> </span><span class="nx">question</span><span class="p">,</span><span class="w"> </span><span class="nx">history</span><span class="o">:</span><span class="w"> </span><span class="nx">history</span><span class="w"> </span><span class="p">})</span>
<span class="w">        </span><span class="p">})</span>
<span class="w">        </span><span class="p">.</span><span class="nx">then</span><span class="p">(</span><span class="nx">response</span><span class="w"> </span><span class="p">=&gt;</span><span class="w"> </span><span class="nx">response</span><span class="p">.</span><span class="nx">json</span><span class="p">())</span>
<span class="w">        </span><span class="p">.</span><span class="nx">then</span><span class="p">(</span><span class="nx">data</span><span class="w"> </span><span class="p">=&gt;</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="c1">// 显示机器人回答</span>
<span class="w">            </span><span class="nx">addMessage</span><span class="p">(</span><span class="nx">data</span><span class="p">.</span><span class="nx">answer</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;bot&#39;</span><span class="p">);</span>

<span class="w">            </span><span class="c1">// 更新 history</span>
<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nb">Array</span><span class="p">.</span><span class="nx">isArray</span><span class="p">(</span><span class="nx">data</span><span class="p">.</span><span class="nx">history</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nx">history</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">data</span><span class="p">.</span><span class="nx">history</span><span class="p">;</span>
<span class="w">            </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nb">Array</span><span class="p">.</span><span class="nx">isArray</span><span class="p">(</span><span class="nx">data</span><span class="p">.</span><span class="nx">new_history</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nx">history</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">data</span><span class="p">.</span><span class="nx">new_history</span><span class="p">;</span>
<span class="w">            </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nx">history</span><span class="p">.</span><span class="nx">push</span><span class="p">([</span><span class="nx">question</span><span class="p">,</span><span class="w"> </span><span class="nx">data</span><span class="p">.</span><span class="nx">answer</span><span class="p">]);</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">})</span>
<span class="w">        </span><span class="p">.</span><span class="k">catch</span><span class="p">(</span><span class="nx">error</span><span class="w"> </span><span class="p">=&gt;</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nx">console</span><span class="p">.</span><span class="nx">error</span><span class="p">(</span><span class="s1">&#39;Error:&#39;</span><span class="p">,</span><span class="w"> </span><span class="nx">error</span><span class="p">);</span>
<span class="w">            </span><span class="nx">addMessage</span><span class="p">(</span><span class="s1">&#39;抱歉，服务暂时不可用，请稍后再试。&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;bot&#39;</span><span class="p">);</span>
<span class="w">        </span><span class="p">});</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="kd">function</span><span class="w"> </span><span class="nx">addMessage</span><span class="p">(</span><span class="nx">text</span><span class="p">,</span><span class="w"> </span><span class="nx">sender</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kd">const</span><span class="w"> </span><span class="nx">chatBox</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">document</span><span class="p">.</span><span class="nx">getElementById</span><span class="p">(</span><span class="s1">&#39;chat-box&#39;</span><span class="p">);</span>
<span class="w">        </span><span class="kd">const</span><span class="w"> </span><span class="nx">messageDiv</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">document</span><span class="p">.</span><span class="nx">createElement</span><span class="p">(</span><span class="s1">&#39;div&#39;</span><span class="p">);</span>
<span class="w">        </span><span class="nx">messageDiv</span><span class="p">.</span><span class="nx">className</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="sb">`message </span><span class="si">${</span><span class="nx">sender</span><span class="si">}</span><span class="sb">-message`</span><span class="p">;</span>

<span class="w">        </span><span class="kd">const</span><span class="w"> </span><span class="nx">now</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ow">new</span><span class="w"> </span><span class="nb">Date</span><span class="p">();</span>
<span class="w">        </span><span class="kd">const</span><span class="w"> </span><span class="nx">timeString</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">now</span><span class="p">.</span><span class="nx">toLocaleTimeString</span><span class="p">([],</span><span class="w"> </span><span class="p">{</span><span class="nx">hour</span><span class="o">:</span><span class="w"> </span><span class="s1">&#39;2-digit&#39;</span><span class="p">,</span><span class="w"> </span><span class="nx">minute</span><span class="o">:</span><span class="s1">&#39;2-digit&#39;</span><span class="p">});</span>

<span class="w">        </span><span class="nx">messageDiv</span><span class="p">.</span><span class="nx">innerHTML</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="sb">`</span>
<span class="sb">            </span><span class="si">${</span><span class="nx">text</span><span class="si">}</span>
<span class="sb">            &lt;div class=&quot;timestamp&quot;&gt;</span><span class="si">${</span><span class="nx">sender</span><span class="w"> </span><span class="o">===</span><span class="w"> </span><span class="s1">&#39;user&#39;</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="s1">&#39;您&#39;</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="s1">&#39;小健康助手&#39;</span><span class="si">}</span><span class="sb"> · </span><span class="si">${</span><span class="nx">timeString</span><span class="si">}</span><span class="sb">&lt;/div&gt;</span>
<span class="sb">        `</span><span class="p">;</span>

<span class="w">        </span><span class="nx">chatBox</span><span class="p">.</span><span class="nx">appendChild</span><span class="p">(</span><span class="nx">messageDiv</span><span class="p">);</span>
<span class="w">        </span><span class="nx">chatBox</span><span class="p">.</span><span class="nx">scrollTop</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">chatBox</span><span class="p">.</span><span class="nx">scrollHeight</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">&lt;/</span><span class="nt">script</span><span class="p">&gt;</span>

<span class="p">&lt;/</span><span class="nt">body</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">html</span><span class="p">&gt;</span>
</code></pre></div>
<ul>
<li>运行app.py文件, 效果如下:</li>
</ul>
<p><img alt="image-20250817163410599" src="img/image-20250817163410599.png" /></p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.50899def.min.js"></script>
      
        <script src="../js/extra.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>