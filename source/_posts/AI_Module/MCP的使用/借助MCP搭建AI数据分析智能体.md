---
date: 2025-05-21 18:32:14
title: å€ŸåŠ©MCPæ­å»ºAIæ•°æ®åˆ†ææ™ºèƒ½ä½“
categories: [AI_Module, å€ŸåŠ©MCPæ­å»ºAIæ•°æ®åˆ†ææ™ºèƒ½ä½“]
tag: AI_Module
---

# å€ŸåŠ©MCPæ­å»ºAIæ•°æ®åˆ†ææ™ºèƒ½ä½“

è¿›è¡ŒMCPæ™ºèƒ½ä½“å¿«é€Ÿå‘å¼€å‘ï¼Œæ¥æ­å»ºä¸€ä¸ªèƒ½å¤Ÿè¿›è¡ŒSQLæŸ¥è¯¢å’ŒPythonè‡ªåŠ¨ç¼–å†™çš„å…¥é—¨çº§æ•°æ®åˆ†ææ™ºèƒ½ä½“ã€‚

## 1ã€åˆ›å»ºé¡¹ç›®

ä½¿ç”¨Pycharmåˆ›å»ºä¸€ä¸ªé¡¹ç›®

## 2ã€é…ç½®MySQL

å®‰è£…å¥½mysqlåï¼Œåˆ›å»ºè¡¨å¹¶æ’å…¥æ•°æ®

```sql
CREATE DATABASE school;
USE school;
-- ç„¶ååˆ›å»ºä¸€ä¸ªè™šæ‹Ÿè¡¨æ ¼ï¼Œé‡Œé¢åŒ…å«äº†10ä½åŒå­¦å„è‡ª3é—¨è¯¾ç¨‹çš„åˆ†æ•°ï¼š
CREATE TABLE students_scores (
    id INT AUTO_INCREMENT PRIMARY KEY,  
    name VARCHAR(50),                   
    course1 INT,                        
    course2 INT,                       
    course3 INT                        
);
INSERT INTO students_scores (name, course1, course2, course3)
VALUES
    ('å­¦ç”Ÿ1', 85, 92, 78),
    ('å­¦ç”Ÿ2', 76, 88, 91),
    ('å­¦ç”Ÿ3', 90, 85, 80),
    ('å­¦ç”Ÿ4', 65, 70, 72),
    ('å­¦ç”Ÿ5', 82, 89, 95),
    ('å­¦ç”Ÿ6', 91, 93, 87),
    ('å­¦ç”Ÿ7', 77, 78, 85),
    ('å­¦ç”Ÿ8', 88, 92, 91),
    ('å­¦ç”Ÿ9', 84, 76, 80),
    ('å­¦ç”Ÿ10', 89, 90, 92);
```

## 3ã€åˆ›å»ºSQL_server.py

- åŠŸèƒ½ç¤ºæ„å›¾

![image-20250909185824488](https://bob-blog-image.oss-cn-shanghai.aliyuncs.com/MCP_imgs/image-20250909185824488.png)

- ä»£ç å¦‚ä¸‹ï¼š

```python
import json
import httpx
from typing import Any
import pymysql
import csv
from mcp.server.fastmcp import FastMCP

# åˆå§‹åŒ– MCP æœåŠ¡å™¨
mcp = FastMCP("SQLServer")
USER_AGENT = "SQLserver-app/1.0"


@mcp.tool()
async def sql_inter(sql_query):
    """
    æŸ¥è¯¢æœ¬åœ°MySQLæ•°æ®åº“ï¼Œé€šè¿‡è¿è¡Œä¸€æ®µSQLä»£ç æ¥è¿›è¡Œæ•°æ®åº“æŸ¥è¯¢ã€‚\
    :param sql_query: å­—ç¬¦ä¸²å½¢å¼çš„SQLæŸ¥è¯¢è¯­å¥ï¼Œç”¨äºæ‰§è¡Œå¯¹MySQLä¸­schoolæ•°æ®åº“ä¸­å„å¼ è¡¨è¿›è¡ŒæŸ¥è¯¢ï¼Œå¹¶è·å¾—å„è¡¨ä¸­çš„å„ç±»ç›¸å…³ä¿¡æ¯
    :returnï¼šsql_queryåœ¨MySQLä¸­çš„è¿è¡Œç»“æœã€‚
    """

    connection = pymysql.connect(
        host='localhost',  # æ•°æ®åº“åœ°å€
        user='root',  # æ•°æ®åº“ç”¨æˆ·å
        passwd='root',  # æ•°æ®åº“å¯†ç 
        db='school',  # æ•°æ®åº“å
        charset='utf8'  # å­—ç¬¦é›†é€‰æ‹©utf8
    )

    try:
        with connection.cursor() as cursor:
            # SQLæŸ¥è¯¢è¯­å¥
            sql = sql_query
            cursor.execute(sql)

            # è·å–æŸ¥è¯¢ç»“æœ
            results = cursor.fetchall()

    finally:
        connection.close()

    return json.dumps(results)


@mcp.tool()
async def export_table_to_csv(table_name, output_file):
    """
    å°† MySQL æ•°æ®åº“ä¸­çš„æŸä¸ªè¡¨å¯¼å‡ºä¸º CSV æ–‡ä»¶ã€‚

    :param table_name: éœ€è¦å¯¼å‡ºçš„è¡¨å
    :param output_file: è¾“å‡ºçš„ CSV æ–‡ä»¶è·¯å¾„
    """
    # è¿æ¥ MySQL æ•°æ®åº“
    connection = pymysql.connect(
        host='localhost',  # æ•°æ®åº“åœ°å€
        user='root',  # æ•°æ®åº“ç”¨æˆ·å
        passwd='root',  # æ•°æ®åº“å¯†ç 
        db='school',  # æ•°æ®åº“å
        charset='utf8'  # å­—ç¬¦é›†
    )

    try:
        with connection.cursor() as cursor:
            # æŸ¥è¯¢æ•°æ®è¡¨çš„æ‰€æœ‰æ•°æ®
            query = f"SELECT * FROM {table_name};"
            cursor.execute(query)

            # è·å–æ‰€æœ‰åˆ—å
            column_names = [desc[0] for desc in cursor.description]

            # è·å–æŸ¥è¯¢ç»“æœ
            rows = cursor.fetchall()

            # å°†æ•°æ®å†™å…¥ CSV æ–‡ä»¶
            with open(output_file, mode='w', newline='', encoding='utf-8') as file:
                writer = csv.writer(file)

                # å†™å…¥è¡¨å¤´
                writer.writerow(column_names)

                # å†™å…¥æ•°æ®
                writer.writerows(rows)

            print(f"æ•°æ®è¡¨ {table_name} å·²æˆåŠŸå¯¼å‡ºè‡³ {output_file}")

    except Exception as e:
        print(f"å¯¼å‡ºå¤±è´¥: {e}")

    finally:
        connection.close()


if __name__ == "__main__":
    # ä»¥æ ‡å‡† I/O æ–¹å¼è¿è¡Œ MCP æœåŠ¡å™¨
    mcp.run(transport='stdio')
```



## 4ã€åˆ›å»ºPython_server.py

åŠŸèƒ½ç¤ºæ„å›¾ï¼š

![image-20250909190123864](https://bob-blog-image.oss-cn-shanghai.aliyuncs.com/MCP_imgs/image-20250909190123864.png)

ä»£ç å¦‚ä¸‹ï¼š

```python
import json
from typing import Any
import csv
import numpy as np
import pandas as pd
import random
from mcp.server.fastmcp import FastMCP

# åˆå§‹åŒ– MCP æœåŠ¡å™¨
mcp = FastMCP("PythonServer")
USER_AGENT = "Pythonserver-app/1.0"


@mcp.tool()
async def python_inter(py_code):
    """
    è¿è¡Œç”¨æˆ·æä¾›çš„ Python ä»£ç ï¼Œå¹¶è¿”å›æ‰§è¡Œç»“æœã€‚

    :param py_code: å­—ç¬¦ä¸²å½¢å¼çš„ Python ä»£ç 
    :return: ä»£ç è¿è¡Œçš„æœ€ç»ˆç»“æœ
    """
    # è·å–å…¨å±€ä½œç”¨åŸŸçš„å˜é‡å­—å…¸ï¼Œåç»­æ‰§è¡Œ eval æˆ– exec æ—¶ä¼šç”¨åˆ°ã€‚
    g = globals()

    try:
        # è‹¥æ˜¯è¡¨è¾¾å¼ã€æœ‰è¿”å›å€¼çš„è¯­å¥ï¼Œä¾‹å¦‚ "1+2", "len([1,2,3])"ã€‘ï¼Œç›´æ¥è¿è¡Œå¹¶è¿”å›
        result = eval(py_code, g)
        return json.dumps(str(result), ensure_ascii=False)

    except Exception:
        global_vars_before = set(g.keys())  # è®°å½•æ‰§è¡Œå‰çš„å…¨å±€å˜é‡é›†åˆ
        try:
            # exec æ‰§è¡Œè¯­å¥ï¼ˆå¦‚ for å¾ªç¯ã€å‡½æ•°å®šä¹‰ã€å˜é‡èµ‹å€¼ç­‰ï¼‰
            exec(py_code, g)
        except Exception as e:
            return json.dumps(f"ä»£ç æ‰§è¡Œæ—¶æŠ¥é”™: {e}", ensure_ascii=False)

        global_vars_after = set(g.keys())
        # è·å–æ‰§è¡Œåçš„å…¨å±€å˜é‡é›†åˆï¼Œæ‰¾å‡ºæ–°å¢åŠ çš„å˜é‡
        new_vars = global_vars_after - global_vars_before

        if new_vars:
            # åªè¿”å›å¯åºåˆ—åŒ–çš„å˜é‡å€¼
            safe_result = {}
            for var in new_vars:
                try:
                    json.dumps(g[var])  # å°è¯•åºåˆ—åŒ–ï¼Œç¡®ä¿å¯ä»¥è½¬æ¢ä¸º JSON
                    safe_result[var] = g[var]
                except (TypeError, OverflowError):
                    safe_result[var] = str(g[var])  # å¦‚æœä¸èƒ½åºåˆ—åŒ–ï¼Œåˆ™è½¬æ¢ä¸ºå­—ç¬¦ä¸²

            return json.dumps(safe_result, ensure_ascii=False)

        else:
            return json.dumps("å·²ç»é¡ºåˆ©æ‰§è¡Œä»£ç ", ensure_ascii=False)


if __name__ == "__main__":
    # ä»¥æ ‡å‡† I/O æ–¹å¼è¿è¡Œ MCP æœåŠ¡å™¨
    mcp.run(transport='stdio')

```

## 5ã€åˆ›å»ºå…¶ä»–æœåŠ¡å™¨

- weather_server.py

```python
import json
import httpx
from typing import Any
from mcp.server.fastmcp import FastMCP

# åˆå§‹åŒ– MCP æœåŠ¡å™¨
mcp = FastMCP("WeatherServer")

# OpenWeather API é…ç½®
OPENWEATHER_API_BASE = "https://api.openweathermap.org/data/2.5/weather"
API_KEY = "47436a80e35d8a0f3ca9fb9cb4f2f1bc"  # è¯·æ›¿æ¢ä¸ºä½ è‡ªå·±çš„ OpenWeather API Key
USER_AGENT = "weather-app/1.0"

async def fetch_weather(city: str) -> dict[str, Any] | None:
    """
    ä» OpenWeather API è·å–å¤©æ°”ä¿¡æ¯ã€‚
    :param city: åŸå¸‚åç§°ï¼ˆéœ€ä½¿ç”¨è‹±æ–‡ï¼Œå¦‚ Beijingï¼‰
    :return: å¤©æ°”æ•°æ®å­—å…¸ï¼›è‹¥å‡ºé”™è¿”å›åŒ…å« error ä¿¡æ¯çš„å­—å…¸
    """
    params = {
        "q": city,
        "appid": API_KEY,
        "units": "metric",
        "lang": "zh_cn"
    }
    headers = {"User-Agent": USER_AGENT}

    async with httpx.AsyncClient() as client:
        try:
            response = await client.get(OPENWEATHER_API_BASE, params=params, headers=headers, timeout=30.0)
            response.raise_for_status()
            return response.json()  # è¿”å›å­—å…¸ç±»å‹
        except httpx.HTTPStatusError as e:
            return {"error": f"HTTP é”™è¯¯: {e.response.status_code}"}
        except Exception as e:
            return {"error": f"è¯·æ±‚å¤±è´¥: {str(e)}"}

def format_weather(data: dict[str, Any] | str) -> str:
    """
    å°†å¤©æ°”æ•°æ®æ ¼å¼åŒ–ä¸ºæ˜“è¯»æ–‡æœ¬ã€‚
    :param data: å¤©æ°”æ•°æ®ï¼ˆå¯ä»¥æ˜¯å­—å…¸æˆ– JSON å­—ç¬¦ä¸²ï¼‰
    :return: æ ¼å¼åŒ–åçš„å¤©æ°”ä¿¡æ¯å­—ç¬¦ä¸²
    """
    # å¦‚æœä¼ å…¥çš„æ˜¯å­—ç¬¦ä¸²ï¼Œåˆ™å…ˆè½¬æ¢ä¸ºå­—å…¸
    if isinstance(data, str):
        try:
            data = json.loads(data)
        except Exception as e:
            return f"æ— æ³•è§£æå¤©æ°”æ•°æ®: {e}"

    # å¦‚æœæ•°æ®ä¸­åŒ…å«é”™è¯¯ä¿¡æ¯ï¼Œç›´æ¥è¿”å›é”™è¯¯æç¤º
    if "error" in data:
        return f"âš ï¸ {data['error']}"

    # æå–æ•°æ®æ—¶åšå®¹é”™å¤„ç†
    city = data.get("name", "æœªçŸ¥")
    country = data.get("sys", {}).get("country", "æœªçŸ¥")
    temp = data.get("main", {}).get("temp", "N/A")
    humidity = data.get("main", {}).get("humidity", "N/A")
    wind_speed = data.get("wind", {}).get("speed", "N/A")
    # weather å¯èƒ½ä¸ºç©ºåˆ—è¡¨ï¼Œå› æ­¤ç”¨ [0] å‰å…ˆæä¾›é»˜è®¤å­—å…¸
    weather_list = data.get("weather", [{}])
    description = weather_list[0].get("description", "æœªçŸ¥")

    return (
        f"ğŸŒ {city}, {country}\n"
        f"ğŸŒ¡ æ¸©åº¦: {temp}Â°C\n"
        f"ğŸ’§ æ¹¿åº¦: {humidity}%\n"
        f"ğŸŒ¬ é£é€Ÿ: {wind_speed} m/s\n"
        f"ğŸŒ¤ å¤©æ°”: {description}\n"
    )

@mcp.tool()
async def query_weather(city: str) -> str:
    """
    è¾“å…¥æŒ‡å®šåŸå¸‚çš„è‹±æ–‡åç§°ï¼Œè¿”å›ä»Šæ—¥å¤©æ°”æŸ¥è¯¢ç»“æœã€‚
    :param city: åŸå¸‚åç§°ï¼ˆéœ€ä½¿ç”¨è‹±æ–‡ï¼‰
    :return: æ ¼å¼åŒ–åçš„å¤©æ°”ä¿¡æ¯
    """
    data = await fetch_weather(city)
    return format_weather(data)

if __name__ == "__main__":
    # ä»¥æ ‡å‡† I/O æ–¹å¼è¿è¡Œ MCP æœåŠ¡å™¨
    mcp.run(transport='stdio')
```

- write_server.py

```python
from mcp.server.fastmcp import FastMCP

# åˆå§‹åŒ– MCP æœåŠ¡å™¨
mcp = FastMCP("WriteServer")



@mcp.tool()
async def write_file(content):
    """
    å°†æŒ‡å®šå†…å®¹å†™å…¥æœ¬åœ°æ–‡ä»¶ã€‚
    :param content: å¿…è¦å‚æ•°ï¼Œå­—ç¬¦ä¸²ç±»å‹ï¼Œç”¨äºè¡¨ç¤ºéœ€è¦å†™å…¥æ–‡æ¡£çš„å…·ä½“å†…å®¹ã€‚
    :returnï¼šæ˜¯å¦æˆåŠŸå†™å…¥
    """
    
    return "å·²æˆåŠŸå†™å…¥æœ¬åœ°æ–‡ä»¶ã€‚"


if __name__ == "__main__":
    # ä»¥æ ‡å‡† I/O æ–¹å¼è¿è¡Œ MCP æœåŠ¡å™¨
    mcp.run(transport='stdio')
```



## 6ã€åˆ›å»ºMCPå®¢æˆ·ç«¯Client

æ¥ä¸‹æ¥è€ƒè™‘åˆ›å»ºå®¢æˆ·ç«¯Clientï¼Œæ­¤æ—¶å®¢æˆ·ç«¯éœ€è¦æ»¡è¶³ä»¥ä¸‹å‡ ç‚¹è¦æ±‚ï¼š

- åŒæ—¶è¿æ¥å¤šä¸ªæœåŠ¡å™¨ä¸Šçš„è‹¥å¹²ä¸ªå·¥å…·ï¼›

- éœ€è¦èƒ½å¤ŸåŒæ—¶å®Œæˆä¸²è”æˆ–è€…å¹¶è”æ¨¡å¼ï¼›

- éœ€è¦èƒ½å¤Ÿæ”¯æŒå¤šè½®å¯¹è¯ã€‚

![ss](https://bob-blog-image.oss-cn-shanghai.aliyuncs.com/MCP_imgs/ss-17574159613601.png)

ä»£ç å¦‚ä¸‹ï¼š

```python
import asyncio
import os
import json
from typing import Optional, Dict, Any, List, Tuple
from contextlib import AsyncExitStack

from openai import OpenAI
from dotenv import load_dotenv

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

load_dotenv()


class MultiServerMCPClient:
    def __init__(self):
        """ç®¡ç†å¤šä¸ª MCP æœåŠ¡å™¨çš„å®¢æˆ·ç«¯"""
        self.exit_stack = AsyncExitStack()
        self.openai_api_key = os.getenv("api_key")
        self.base_url = os.getenv("base_url")
        self.model = os.getenv("model_name")
        if not self.openai_api_key:
            raise ValueError("âŒ æœªæ‰¾åˆ° openai_api_keyï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®")

        # OpenAI Clientï¼ˆåŒæ­¥ APIï¼‰
        self.client = OpenAI(api_key=self.openai_api_key, base_url=self.base_url)

        # å­˜å‚¨ (server_name -> MCP ClientSession) æ˜ å°„
        self.sessions: Dict[str, ClientSession] = {}
        # å­˜å‚¨å·¥å…·ä¿¡æ¯
        self.tools_by_session: Dict[str, list] = {}  # æ¯ä¸ª session çš„ tools åˆ—è¡¨
        self.all_tools: List[dict] = []  # åˆå¹¶æ‰€æœ‰å·¥å…·çš„åˆ—è¡¨

    async def connect_to_servers(self, servers: dict):
        """
        servers: {"weather": "weather_server.py", "rag": "rag_server.py"}
        """
        for server_name, script_path in servers.items():
            session = await self._start_one_server(script_path)
            self.sessions[server_name] = session

            resp = await session.list_tools()
            # resp.tools é€šå¸¸æ˜¯ä¸€ä¸ªå·¥å…·æè¿°åˆ—è¡¨
            self.tools_by_session[server_name] = resp.tools

            for tool in resp.tools:
                # æŠŠ MCP tool è½¬æˆ LLM å¯è§çš„å·¥å…·å¯¹è±¡ï¼ˆè¿™é‡Œé‡‡ç”¨ type/function åŒ…è£…ï¼‰
                function_name = f"{server_name}_{tool.name}"
                # tool é‡Œå¯èƒ½æœ‰: name, description, inputSchema æˆ– input_schema
                input_schema = getattr(tool, "inputSchema", None) or getattr(tool, "input_schema", None) or {}
                self.all_tools.append({
                    "type": "function",
                    "function": {
                        "name": function_name,
                        "description": tool.description if hasattr(tool, "description") else "",
                        "input_schema": input_schema
                    }
                })

        # å°† input_schema è½¬æˆ OpenAI/å·¥å…·ç³»ç»ŸæœŸæœ›çš„ parameters ç»“æ„
        self.all_tools = await self.transform_json(self.all_tools)

        print("\nâœ… å·²è¿æ¥åˆ°ä¸‹åˆ—æœåŠ¡å™¨:")
        for name in servers:
            print(f"  - {name}: {servers[name]}")
        print("\næ±‡æ€»çš„å·¥å…·:")
        for t in self.all_tools:
            # è¿™é‡Œ t çš„ç»“æ„ä¿ç•™ {"type":"function","function":{...}}
            print(f"  - {t['function']['name']}")

    async def transform_json(self, json2_data):
        """
        å°† {"type":"function","function":{"name":..,"description":..,"input_schema":{...}}}
        è½¬ä¸ºä¿æŒåŒæ ·å¤–å±‚ä½†æŠŠ input_schema -> parameters
        """
        result = []
        for item in json2_data:
            if not isinstance(item, dict) or "type" not in item or "function" not in item:
                continue
            old_func = item["function"]
            if not isinstance(old_func, dict) or "name" not in old_func or "description" not in old_func:
                continue

            new_func = {
                "name": old_func["name"],
                "description": old_func["description"],
                "parameters": {}
            }

            if "input_schema" in old_func and isinstance(old_func["input_schema"], dict):
                old_schema = old_func["input_schema"]
                new_func["parameters"]["type"] = old_schema.get("type", "object")
                new_func["parameters"]["properties"] = old_schema.get("properties", {})
                new_func["parameters"]["required"] = old_schema.get("required", [])

            result.append({
                "type": item["type"],
                "function": new_func
            })
        return result

    async def _start_one_server(self, script_path: str) -> ClientSession:
        is_python = script_path.endswith(".py")
        is_js = script_path.endswith(".js")
        if not (is_python or is_js):
            raise ValueError("æœåŠ¡å™¨è„šæœ¬å¿…é¡»æ˜¯ .py æˆ– .js æ–‡ä»¶")

        command = "python" if is_python else "node"
        server_params = StdioServerParameters(
            command=command,
            args=[script_path],
            env=None
        )
        # ä½¿ç”¨ AsyncExitStack ç®¡ç†ç”Ÿå‘½å‘¨æœŸ
        stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))
        read_stream, write_stream = stdio_transport
        session = await self.exit_stack.enter_async_context(ClientSession(read_stream, write_stream))
        await session.initialize()
        return session

    # helper: æŠŠ CallToolResult ç»Ÿä¸€è½¬æ¢æˆå­—ç¬¦ä¸²ï¼ˆä¼˜å…ˆç»“æ„åŒ– dataï¼‰
    def extract_tool_result(self, call_tool_result: Any) -> str:
        # 1) ä¼˜å…ˆå–ç»“æ„åŒ–æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
        data = getattr(call_tool_result, "data", None)
        if data is not None:
            try:
                return json.dumps(data, ensure_ascii=False)
            except Exception:
                return str(data)

        # 2) å›é€€åˆ° content blocksï¼ˆå¸¸è§ä¸ºåˆ—è¡¨ï¼Œæ¯ä¸ª block å¯èƒ½æœ‰ .text æˆ– .content å­—æ®µï¼‰
        content = getattr(call_tool_result, "content", None)
        if content:
            parts: List[str] = []
            for block in content:
                # block å¯èƒ½æ˜¯å¯¹è±¡æˆ– dict
                text = None
                if isinstance(block, dict):
                    text = block.get("text") or block.get("content") or str(block)
                else:
                    # å¯¹è±¡å¯èƒ½æœ‰ text å±æ€§
                    text = getattr(block, "text", None) or getattr(block, "content", None)
                if text is None:
                    # fallback: å°è¯•ç›´æ¥ str()
                    text = str(block)
                parts.append(text)
            return "\n".join(parts)

        # 3) å…œåº•
        return "å·¥å…·æ‰§è¡Œæ— è¾“å‡º"

    # æŠŠ OpenAI API çš„åŒæ­¥è°ƒç”¨æ”¾åˆ°çº¿ç¨‹æ± ï¼Œé¿å…é˜»å¡ event loop
    async def _call_openai_sync(self, /, *args, **kwargs):
        return await asyncio.to_thread(self.client.chat.completions.create, *args, **kwargs)

    async def chat_base(self, messages: list) -> Any:
        """
        messages: list of dicts: {"role":..., "content":...}
        è¿”å› OpenAI response å¯¹è±¡ï¼ˆåŒæ­¥ responseï¼Œä½†æˆ‘ä»¬åœ¨çº¿ç¨‹é‡Œè°ƒç”¨ï¼‰
        """
        response = await self._call_openai_sync(
            model=self.model,
            messages=messages,
            tools=self.all_tools
        )

        # è‹¥æ¨¡å‹é€‰æ‹©äº†è°ƒç”¨å·¥å…·( finish_reason == "tool_calls" )
        # åå¤å¤„ç† tool call loopï¼ˆç›´åˆ°æ¨¡å‹ä¸å†è¦æ±‚å·¥å…·ï¼‰
        while getattr(response.choices[0], "finish_reason", None) == "tool_calls":
            messages = await self.create_function_response_messages(messages, response)
            response = await self._call_openai_sync(
                model=self.model,
                messages=messages,
                tools=self.all_tools
            )

        return response

    async def create_function_response_messages(self, messages, response):
        """
        è§£æ response ä¸­çš„ tool_callsï¼Œè°ƒç”¨ MCP å·¥å…·ï¼Œå¹¶æŠŠå·¥å…·ç»“æœåŠ å…¥æ¶ˆæ¯åºåˆ—
        """
        # æŠŠ assistant çš„åŸå§‹æ¶ˆæ¯ä¹ŸåŠ å…¥ï¼ˆæ¨¡å‹çš„ tool_call æ¶ˆæ¯ï¼‰
        # response.choices[0].message å¯èƒ½ä¸º pydantic æ¨¡å‹ï¼Œè½¬æ¢ä¸º dict
        messages.append(response.choices[0].message.model_dump() if hasattr(response.choices[0].message, "model_dump") else response.choices[0].message)

        # éå†æ‰€æœ‰ tool_calls
        function_call_messages = response.choices[0].message.tool_calls or []
        for function_call_message in function_call_messages:
            tool_name = function_call_message.function.name
            try:
                tool_args = json.loads(function_call_message.function.arguments)
            except Exception:
                # arguments å¯èƒ½å·²ç»æ˜¯ dict
                tool_args = getattr(function_call_message.function, "arguments", {}) or {}

            # è¿è¡Œ MCP å·¥å…·
            function_response_raw = await self._call_mcp_tool(tool_name, tool_args)
            # function_response_raw å·²ç»æ˜¯å­—ç¬¦ä¸²ï¼ˆ_call_mcp_tool è¿”å› strï¼‰
            messages.append(
                {
                    "role": "tool",
                    "content": function_response_raw,
                    "tool_call_id": function_call_message.id,
                }
            )
        return messages

    async def process_query(self, user_query: str, messages: Optional[List[Dict[str, Any]]] = None) -> Tuple[str, List[Dict[str, Any]]]:
        """
        å¤„ç†å•ä¸ªç”¨æˆ·æŸ¥è¯¢å¹¶è¿”å›æ¨¡å‹æœ€ç»ˆæ–‡æœ¬è¾“å‡ºä¸æ›´æ–°åçš„æ¶ˆæ¯å†å²ã€‚
        - å°† user_query append åˆ° messagesï¼ˆè‹¥ messages ä¸º None åˆ™æ–°å»ºï¼‰ã€‚
        - ä½¿ç”¨ chat_base() æ¥è¿è¡Œæ¨¡å‹ï¼ˆchat_base å·²å¤„ç† tool_calls çš„å¾ªç¯ï¼‰ã€‚
        - è¿”å› (final_text, messages)
        å¤‡æ³¨ï¼šè¿”å› messages ä»¥ä¾¿å¤–éƒ¨ï¼ˆå¦‚ chat_loopï¼‰ç»´æŠ¤å¯¹è¯å†å²ã€‚
        """
        if messages is None:
            messages = []

        # Append user message
        messages.append({"role": "user", "content": user_query})
        # ä¿æŒå†å²é•¿åº¦ï¼ˆè¿™é‡Œä¿ç•™æœ€è¿‘ 20 æ¡ï¼‰
        messages = messages[-20:]

        # ä½¿ç”¨ chat_baseï¼ˆä¼šè‡ªåŠ¨å¤„ç†å·¥å…·è°ƒç”¨å¾ªç¯ï¼‰
        response = await self.chat_base(messages)

        # response ä¸º OpenAI çš„è¿”å›å¯¹è±¡ï¼›å–æœ€ç»ˆ assistant æ¶ˆæ¯æ–‡æœ¬
        assistant_msg = response.choices[0].message
        # å°è¯•ç›´æ¥å– assistant_msg.content
        final_text = getattr(assistant_msg, "content", None)
        '''
        åœ¨æŸäº› SDKï¼ˆæˆ– Pydanticï¼‰å®ç°é‡Œï¼Œmessage å¯èƒ½æ˜¯ä¸€ä¸ªå¤æ‚çš„ Pydantic å¯¹è±¡æˆ–è‡ªå®šä¹‰å¯¹è±¡ï¼Œç›´æ¥è®¿é—® .content ä¸ä¸€å®šå­˜åœ¨æˆ–ä¸å¯é ã€‚å¾ˆå¤šè¿™ç±»å¯¹è±¡éƒ½æä¾› model_dump()ï¼ˆæˆ–ç±»ä¼¼æ–¹æ³•ï¼‰æŠŠå†…éƒ¨æ•°æ®è½¬æ¢æˆ Python åŸç”Ÿ dictã€‚
        æ‰€ä»¥å½“ç›´æ¥å–ä¸åˆ° content æ—¶ï¼Œè¯•ç€æŠŠå¯¹è±¡â€œæ‘Šå¹³â€æˆ dictï¼Œå†ä» dict é‡Œå– content
        '''
        if final_text is None and hasattr(assistant_msg, "model_dump"):
            md = assistant_msg.model_dump()
            if isinstance(md, dict):
                final_text = md.get("content")
            else:
                final_text = str(md)

        # è‹¥ä»ç„¶æ²¡æœ‰æ–‡æœ¬ï¼ˆç†è®ºä¸å¸¸è§ï¼‰ï¼Œå›é€€ä¸ºæ•´ä¸ª message çš„ str è¡¨ç¤º
        if final_text is None:
            try:
                final_text = str(assistant_msg)
            except Exception:
                final_text = ""

        # æŠŠ assistant æœ€ç»ˆæ¶ˆæ¯åŠ å…¥åˆ°å†å²ï¼ˆç»´æŒä¸ chat_base/å·¥å…·è°ƒç”¨ä¸€è‡´çš„å†å²ï¼‰
        # æ³¨æ„ï¼šchat_base åœ¨è¿”å›ä¹‹å‰å¹¶æ²¡æœ‰æŠŠæœ€åçš„ assistant message append åˆ° messagesï¼ˆé™¤éåœ¨ tool loop ä¸­ï¼‰ã€‚
        # ä¸ºä¿è¯å†å²ä¸€è‡´ï¼Œè¿™é‡Œåšä¸€æ¬¡å®‰å…¨è¿½åŠ ï¼ˆè‹¥æœ€åä¸€æ¡ä¸æ˜¯ assistantï¼Œåˆ™è¿½åŠ ï¼‰
        if not messages or messages[-1].get("role") != "assistant":
            # å°è¯•æŠŠ pydantic message è½¬ä¸ºæ™®é€š dictï¼ˆå…¼å®¹æ€§ï¼‰
            assistant_entry = assistant_msg.model_dump() if hasattr(assistant_msg, "model_dump") else assistant_msg
            messages.append(assistant_entry)

        # æˆªæ–­å†å²ï¼Œé¿å…æ— é™å¢é•¿
        messages = messages[-40:]

        return final_text, messages

    async def _call_mcp_tool(self, tool_full_name: str, tool_args: dict) -> str:
        parts = tool_full_name.split("_", 1)
        if len(parts) != 2:
            return f"æ— æ•ˆçš„å·¥å…·åç§°: {tool_full_name}"

        server_name, tool_name = parts
        session = self.sessions.get(server_name)
        if not session:
            return f"æ‰¾ä¸åˆ°æœåŠ¡å™¨: {server_name}"

        # æ‰§è¡Œ MCP å·¥å…·ï¼ˆå¯èƒ½è¿”å› CallToolResultï¼‰
        resp = await session.call_tool(tool_name, tool_args)
        # æŠŠ resp ç»Ÿä¸€æå–æˆå­—ç¬¦ä¸²
        out = self.extract_tool_result(resp)
        return out

    async def chat_loop(self):
        print("\nğŸ¤– å¤šæœåŠ¡å™¨ MCP + Function Calling å®¢æˆ·ç«¯å·²å¯åŠ¨ï¼è¾“å…¥ 'quit' é€€å‡ºã€‚")
        # messages ä½œä¸ºä¼šè¯å†å²åœ¨ chat_loop ä¸ process_query ä¹‹é—´ä¼ é€’
        messages: List[Dict[str, Any]] = []

        while True:
            # ä½¿ç”¨çº¿ç¨‹è°ƒç”¨ inputï¼Œä»¥å…é˜»å¡ event loop
            query = await asyncio.to_thread(input, "\nä½ : ")
            if query is None:
                continue
            query = query.strip()
            if query.lower() == "quit":
                break

            try:
                # ä½¿ç”¨ process_query å¤„ç†æœ¬æ¬¡è¾“å…¥ï¼ˆprocess_query è¿”å› final_text ä¸æ›´æ–°åçš„ messagesï¼‰
                final_text, messages = await self.process_query(query, messages)
                # æ‰“å°æ¨¡å‹è¾“å‡º
                print(f"\nAI: {final_text}")
            except Exception as e:
                print(f"\nâš ï¸ è°ƒç”¨è¿‡ç¨‹å‡ºé”™: {e}")

    async def cleanup(self):
        await self.exit_stack.aclose()


async def main():
    servers = {
        "write": "write_server.py",
        "weather": "weather_server.py",
        "SQLServer": "SQL_server.py",
        "PythonServer": "Python_server.py"
    }

    client = MultiServerMCPClient()
    try:
        await client.connect_to_servers(servers)
        await client.chat_loop()
    finally:
        await client.cleanup()


if __name__ == "__main__":
    asyncio.run(main())

```

## 7ã€åŠŸèƒ½æµ‹è¯•

- å¯åŠ¨ï¼š

python client.py

- æµ‹è¯•å¤©æ°”ï¼š

è¯·é—®ä»Šå¤©åŒ—äº¬çš„å¤©æ°”å¦‚ä½•ï¼Ÿ

- æµ‹è¯•æ•°æ®åº“ï¼š

```tex
è¯·å¸®æˆ‘æŸ¥è¯¢æ•°æ®åº“ä¸­æ€»å…±åŒ…å«å‡ å¼ è¡¨ï¼Ÿ
è¿™å¼ è¡¨ä¸­æ€»å…±æœ‰å‡ æ¡æ•°æ®ï¼Ÿ
è¯·å¸®æˆ‘å°†è¿™å¼ è¡¨å¯¼å‡ºåˆ°æœ¬åœ°
```

- æµ‹è¯•python

ä½ å¥½ï¼Œè¯·å¸®æˆ‘ç¼–å†™å¹¶è¿è¡Œä¸€æ®µPythonä»£ç ï¼Œæ¥åˆ›å»ºä¸€ä¸ª10ä½çš„éšæœºæ•°

- NL2SQL+NL2PythonåŠŸèƒ½è”åŠ¨æµ‹è¯•

è¯·å¸®æˆ‘è¿è¡ŒPythonä»£ç æ¥è¯»å–æœ¬åœ°students_scores.csvæ–‡ä»¶ï¼Œå¹¶æ‰“å°ç¬¬ä¸€è¡Œæ•°æ®