---
date: 2025-01-27 22:50:18
title: lora微调笔记
categories: [Notes, 微调, lora微调]
---

微调笔记

分类：

fine tuning 传统全量微调，（高质量微调）

prompt tuning（提示词微调）

​	技术：指令微调

​		      上下文学习

​			chain of thought（思维链）

PET模型（Pattern-Exploiting Training）

POFT方法：分成三种类型：（面向提示的微调）

- 全量微调（Full Fine-Tuning）：模型所有参数都参与更新，包括预训练模型参数和下游任务层参数。如PET模型。
- 部分参数微调（Partial Fine-Tuning）：只更新预训练模型中的一部分参数，比如高层 transformer block、某些 attention 层或特定模块，其余参数冻结。如Adapter Tuning。
- 仅提示参数微调（Prompt-Only Tuning）：冻结原始预训练模型参数，只训练 prompt 参数。如P-tuning、Prompt Tuning等。

### Soft Prompt及微调方法

PEFT(参数高效微调)

conda env export > /ptune_chatglm/execute_successful_requir.txt

autodl-tmp/llm_tuning/ptune_chatglm

LoRA

三元组提取（基于用户的输入prompt，送给大模型，做实体提取预测。）

文本分类





问题：

请基于这个html文件，告诉我这是什么任务，基于用户评论的情感分类吗?

lora_rank中lora的每个单词是什么意思

THUDM是什么意思？是组合缩略词吗？拆解开来是哪些单词组成的。合起来是什么意思。尤其在代码中是什么意思？

done

----

谷歌浏览器的添加网页功能很单一，加到一定数量之后，一些网址就隐藏到可视列表之下了，需要滚轮向下翻。我想知道如何把这些添加的网页管理起来，把相似的网页，放到同一个目录下。

请基于上传的两个html文件，告诉我data_process.py文件中，读取的数据



请告诉我在json文件中 \n和\n\n符号的区别？



{"context": "Instruction: 你现在是一个很厉害的阅读理解器，严格按照人类指令进行回答。\nInput: 句子中包含了哪些信息，输出json：\n\n江立，男，瑶族，1978年1月出生，广西恭城人。\nAnswer: ", "target": "```json\n[{\"predicate\": \"出生日期\", \"object_type\": \"Date\", \"subject_type\": \"人物\", \"object\": \"1978年1月\", \"subject\": \"江立\"}, {\"predicate\": \"民族\", \"object_type\": \"Text\", \"subject_type\": \"人物\", \"object\": \"瑶族\", \"subject\": \"江立\"}, {\"predicate\": \"出生地\", \"object_type\": \"地点\", \"subject_type\": \"人物\", \"object\": \"广西恭城\", \"subject\": \"江立\"}]\n```"}

上述句子中句尾\n后的三撇是什么符号？

pandoc "D:\software\fine_tuning\01_课件\site\01-大模型微调主要方式\01-大模型Prompt-Tuning方法.html" -f html -t markdown --wrap=preserve -o "C:\Users\gan\Desktop\输出文件.md"



**批量转换（在 PowerShell 中）：**
打开 PowerShell，导航到你的 HTML 文件所在的文件夹，然后运行：

powershell



复制



下载

```
Get-ChildItem *.html | ForEach-Object { pandoc $_.Name -f html -t markdown -o ($_.BaseName + ".md") }
```

---

```
nvidia-smi 查看cuda版本号
```

----

















